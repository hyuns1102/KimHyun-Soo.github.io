---
title: "[ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ ìº í”„] AI-Tech - Lv2 week2(4)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## í•™ìŠµê¸°ë¡ - 34

ì˜¤ëŠ˜ í•  ì¼

- Multi-modal Learning

## 1. ê°•ì˜ ë³µìŠµ ë‚´ìš©

### Multi-modal Learning

í•œ íƒ€ì…ì— ë°ì´í„°ê°€ ì•„ë‹Œ ë‹¤ë¥¸ íŠ¹ì„±ì˜ ë°ì´í„°ë„ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²ƒ (ì†Œë¦¬, ë§›, ëŠë‚Œ..)

multi-modal learning  
ì—¬ëŸ¬ê°€ì§€ ê°ê° ë°ì´í„°ë¥¼ 'í•¨ê»˜' ì‚¬ìš©í•˜ëŠ” ê²ƒ. ì‚¬ëŒì€ ì¼ë°˜ì ìœ¼ë¡œ multi-modal í˜•íƒœë¡œ ì‚¬ë¬¼ì„ ì¸ì§€í•œë‹¤. (<-> unimodal (í•œê°€ì§€ë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒ))  

- ë¬¸ì œì   

  - ë‹¤ë¥¸ ë°ì´í„° êµ¬ì¡°  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img52.png){: width="" height=""}  

  - featureì˜ Unbalance matching  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img53.png){: width="" height=""}  

  - Specific dataì— ë” biasedí•œ í˜•íƒœë¡œ trainig  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img54.png){: width="" height=""}  

  - ë¬¸ì œì ì´ ìˆìŒì—ë„ ë‹¤ì–‘í•œ ë°©ë²•ì„ í†µí•´ ìœ ìµí•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img55.png){: width="" height=""}  

- Text embedding  

  word embeddingì„ í†µí•´ì„œ ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ 'ë‹¨ì–´'ë“¤ì— ëŒ€í•´ ì¼ë°˜í™”ê°€ ê°€ëŠ¥í•˜ë‹¤.
    ![Untitled](/assets/images/AI-Images2/lv2_week2/img56.png){: width="200px" height="200px"}  

  - Skip-gram model

    input layer -> hidden layer  
    input layerì— ìˆëŠ” vectorëŠ” ì–´ë–¤ ë‹¨ì–´ë“¤ì˜ ë²¡í„°ì´ê³  ë‹¨ì–´ê°€ Wì— ì˜í•´ hidden layerë¡œ ëœë‹¤. ì–´ë–¤ ë‹¨ì–´ì— ëŒ€í•œ íŠ¹ì§•ì„ ì¶”ì¶œí•œë‹¤.  
    hidden layer -> output layer  
    ë‹¨ì–´ ì „ í›„ì˜ ì–´ë–¤ ë‹¨ì–´ê°€ ì˜¤ëŠëƒì— ë”°ë¼ output layerì˜ feature ê²°ì •í•´ì„œ í•™ìŠµí•œë‹¤.  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img57.png){: width="" height=""}

    Skip-gram modelì€ neighboring N wordsì— ëŒ€í•´ì„œ í•™ìŠµí•´ì„œ ì£¼ë³€ ë‹¨ì–´ë“¤ê³¼ì˜ 'ê´€ê³„'ì— ëŒ€í•´ í•™ìŠµí•œë‹¤.  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img58.png){: width="" height=""}

- Joint embedding (Matching)  
  Image tagging  
  Image -> tag or tag -> Image  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img59.png){: width="" height=""}

  Joint embeddingì—ì„œëŠ” ê° Dataì˜ featureë¥¼ ì¶”ì¶œí•œ í›„, ê°™ì€ dimensionìœ¼ë¡œ ë§Œë“  outputì˜ ê±°ë¦¬ì— ë”°ë¥¸ ìƒê´€ì„±ì„ ë‚˜íƒ€ë‚¸ë‹¤.  
  ì´ë ‡ê²Œ matchingì˜ ì •ë„ì— ë”°ë¼ ë°€ê³  (push) ë‹¹ê¸°ëŠ” (pull) í•™ìŠµì„ **metric learning** ì´ë¼ê³  í•œë‹¤.

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img60.png){: width="" height=""}

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img61.png){: width="" height=""}

  - Image tagging - interesting property
    dog Image - 'dog' + 'cat' -> cat Image + dog Image's background  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img62.png){: width="" height=""}

  - Image tagging - food Image vs recipe text
    recipeê³¼ Imageì˜ jointë¥¼ í†µí•´ cosine simmilarity loss ì™€ semantic regularization lossë¥¼ ë§Œë“ ë‹¤.  
    cosine simmilarity lossëŠ” Imageì™€ recipeì˜ ìƒê´€ì„±,  
    semantic regularization lossëŠ” cosine simmilarity lossë¡œ í•´ê²°ì´ ì•ˆë˜ëŠ” ë¶€ë¶„ì— ëŒ€í•´ ê°€ì´ë“œë¥¼ ì¤€ë‹¤. (high-level semantic)

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img63.png){: width="" height=""}

- Cross modal translation (Translating)  

  - Image captioning
    Imageê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì´ë¯¸ì§€ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì¥ ì¶œë ¥

    - show and tell  
      Encoder : CNN modelì„ í†µí•´ì„œ feature ì¶”ì¶œ  
      Decoder : Encoderì—ì„œ ì¶”ì¶œí•œ featureë¥¼ conditionìœ¼ë¡œ í•˜ëŠ” LSTM moduleë‚´ì— RNNì„ í†µí•´ ë‹¨ì–´ ì¶”ì¶œ -> sentence

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img64.png){: width="" height=""}

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img65.png){: width="" height=""}

    - show, attend and tell
      Image ë‚´ì— íŠ¹ì • ì˜ì—­ì„ í™•ì¸í•˜ê³  ì•Œë§ëŠ” sentence ì¶œë ¥  
      Imageì—ì„œ CNNì„ í†µí•´ì„œ convolutional feature ì¶”ì¶œ, RNNì—ì„œ attend ëœ ë¶€ë¶„ì— word generation  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img66.png){: width="" height=""}

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img67.png){: width="" height=""}

    - show, attend and tell (soft attention)  
      attentionì€ ì¸ê°„ì´ ì‚¬ë¬¼ì„ ë³¼ ë•Œ ë³´ëŠ” ë°©ë²•ê³¼ ì¼ì¹˜í•˜ë‹¤. ì¸ê°„ì´ ë³´ëŠ” ë°©ë²•ê³¼ ë¹„ìŠ·í•˜ê²Œ í•˜ê¸° ìœ„í•´ Imageì˜ íŠ¹ì§•ì ì¸ ë¶€ë¶„ì„ ë”°ì„œ ì£¼ìš” ë¶€ë¶„ë§Œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.  

      Imageë¥¼ CNNì— ë„£ì–´ feature vectorë¥¼ gridë¡œ ë‚˜íƒ€ë‚´ê³  ê° featureì— ëŒ€í•´ì„œ RNNì„ í†µê³¼ì‹œì¼œì„œ ì–´ë””ë¥¼ referenceë¥¼ ì¤˜ì•¼í•˜ëŠ” ì§€ heat mapìœ¼ë¡œ ë‚˜íƒ€ë‚´ì¤€ë‹¤.  
      feature vectorì™€ heat mapì—ì„œ feature ë“¤ì˜ probablityë¥¼ weighted sum í•´ì¤˜ì„œ zë¡œ ë‚˜íƒ€ë‚¸ë‹¤.  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img68.png){: width="" height=""}

      ìœ„ì˜ ë‚´ìš©ì„ ë” ìì„¸í•œ ê³¼ì •ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´,  
      Imageë¥¼ CNNìœ¼ë¡œ í†µê³¼í•´ì„œ feature vectorë¥¼ ë‚˜íƒ€ë‚´ì¤€ë‹¤. ì´ê²ƒì„ LSTMì˜ conditionìœ¼ë¡œ ë„£ì–´ì¤€ë‹¤. (h0) LSTMì—ì„œ ì–´ë”” ë¶€ë¶„ì€ attention í•  ì§€ spatial attentionì„ weightë¡œ ì¶œë ¥ í•´ì¤€ë‹¤. (s1)  
      ì´ weightë¥¼ ì´ìš©í•´ì„œ features ì™€ inner productë¥¼ í•´ì¤ë‹ˆë‹¤. (s1, features -> z1)  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img69.png){: width="" height=""}  

      ì—¬ê¸°ì„œ z1ì„ ë‹¤ìŒ RNN step (LSTM) ì— conditionìœ¼ë¡œ ë„£ì–´ì£¼ê²Œ ë˜ê³ , start word tokenì„ ë„£ì–´ì¤€ë‹¤. (h1) h1ì—ì„œ conditionì„ ë³´ê³  ì–´ë–¤ ë‹¨ì–´ë¡œ ì‹œì‘í•´ì•¼í•  ì§€ ê³ ë¯¼ì„ í•˜ê³  wordë¥¼ ì¶”ì¶œ í•œë‹¤. (d1) ë™ì‹œì—, ì–´ë””ë¥¼ reference í•  ê²ƒì¸ì§€ Imageë¥¼ ì¶”ì¶œí•´ì¤€ë‹¤.(s2)  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img70.png){: width="" height=""}  

      ì´ì „ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ featureì™€ weightë¥¼ inner productí•´ì„œ z2ë¥¼ ë§Œë“¤ì–´ì£¼ê³ , LSTMì— ë„£ì–´ì¤€ë‹¤.  
      ì´ ë•Œ tokenì€ ì´ì „ì— ì¶œë ¥í–ˆë˜ ë‹¨ì–´ë¥¼ ë„£ì–´ì¤€ë‹¤.  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img71.png){: width="" height=""}  

      ì´ì „ì— í–ˆë˜ ë°©ì‹ì„ ë°˜ë³µí•˜ë©´ sentenceë¥¼ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆë‹¤.  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img72.png){: width="" height=""}  

  - Text-to-Image
    ì´ë²ˆì—” ì•„ê¹Œí–ˆë˜ ê²ƒê³¼ ë°˜ëŒ€ë¡œ textë¥¼ ì¸ì‹í•˜ê³  Imageë¥¼ outputìœ¼ë¡œ í•˜ëŠ” ë°©ë²•ì´ë‹¤. Generative model (cGAN) ì„ ì´ìš©í•´ì„œ í•™ìŠµì„ ì§„í–‰í•œë‹¤.  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img74.png){: width="" height=""}  

    ë¨¼ì € sentence (condition) ë¥¼ pre-trained networkì— ë„£ì–´ fixed-dimensional vectorë¥¼ ë§Œë“ ë‹¤. ì—¬ê¸°ì— Gaussian Random Code vectorë¥¼ ë¶™ì—¬ì„œ (z~N(0,1)) Networkì— ë„£ì–´ decoderì—ì„œ Imageë¥¼ ì¶œë ¥í•´ì¤€ë‹¤.  
    ì´ ë•Œ, Gaussian Random codeëŠ” ê²°ê³¼ê°€ ë” diverseí•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.  

    ì—¬ê¸°ì„œ ì¶œë ¥ëœ Imageë¥¼ low-dimensionalë¡œ ë§Œë“¤ì–´ì„œ ì´ì „ sentence (condition) ì„ ë„£ì–´ True or Falseë¥¼ ê²°ì •í•œë‹¤.  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img73.png){: width="" height=""}

    ì´ì „ì— í–ˆë˜ cGANì˜ architecturì™€ ë§¤ìš° ë¹„ìŠ·í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.  

- Cross modal reasoning (Referencing)
  ì„œë¡œ ì°¸ì¡°ë¥¼ í•˜ëŠ” ëª¨ë¸  

  - Visual question answering - Multiple streams
    Image stream, Question streamì— ëŒ€í•´ì„œ ê°ê° fixed dimension ì¶œë ¥  
    point-wise multiplicationë¥¼ ì´ìš© (Joint-Embedding)  
    End-to-end training  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img75.png){: width="" height=""}

- Multi-modal tasks (2) - Visual data & Audio

  - Sound representation - Fourier Transform  
    ![Untitled](/assets/images/AI-Images2/lv2_week2/img76.png){: width="" height=""}

    FT decomposes an input signal into constituent frequencies  
    ![Untitled](/assets/images/AI-Images2/lv2_week2/img77.png){: width="" height=""}

    Spectrogram: A stack of spectrums along the time axis  
    ![Untitled](/assets/images/AI-Images2/lv2_week2/img78.png){: width="" height=""}

  - Joint embedding  
    ì˜¤ë””ì˜¤ì— ë”°ë¥¸ Image  
    - Sound Net  
    Train by teacher-student manner  
    Visual to Sound  
    Raw Waveform  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img79.png){: width="" height=""}

    Target taskê°€ ìˆì„ ê²½ìš°, pool5 feature ì¶”ì¶œí•˜ê³  classifierë¥¼ ì˜¬ë ¤ì„œ ë½‘ì•„ë‚¸ë‹¤.  
    conv8 ì´í›„ ì¶œë ¥ ê°’ì„ Object, Sceneì— ë”°ë¼ê°ˆ ê²ƒì´ê¸° ë•Œë¬¸ì— pool5ê°€ generalizable semantic infoê°€ ìˆì„ ê²ƒì´ë¼ ì˜ˆìƒ  
      ![Untitled](/assets/images/AI-Images2/lv2_week2/img80.png){: width="" height=""}

  - Cross modal translation (translate)

    - Speech2Face (oh et al, CVPR 2019)
      soundë¥¼ ì´ìš©í•´ì„œ ì–¼êµ´ ì¶”ì¶œ
      teacher-student ë°©ì‹ìœ¼ë¡œ í›ˆë ¨, Testì‹œì—ëŠ” Speech2Face Model
        ![Untitled](/assets/images/AI-Images2/lv2_week2/img81.png){: width="" height=""}

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img82.png){: width="" height=""}

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img83.png){: width="" height=""}

    - Image-to-speech synthesis - Module networks  
      Speech to Unit modelì„ ì´ìš©í•´ì„œ Unit ìƒì„±, Imageë¥¼ ì´ìš©í•´ì„œ Speech ìƒì„± ì‹œ ì´ìš©  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img84.png){: width="" height=""}

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img85.png){: width="" height=""}

  - Sound source localization (Referencing)  
    Sound + localization  
    ì†Œë¦¬ì™€ ë§¤ì¹­ ë˜ëŠ” Attentioní•œ Imageë¥¼ ì°¾ëŠ”ë‹¤.  
  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img86.png){: width="" height=""}

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img87.png){: width="" height=""}

    Visual netì—ì„œ ë½‘ì€ featureê³¼ Audioì—ì„œ ë½‘ì€ featureì˜ ë‚´ì ì„ í†µí•´ Attention Net ìƒì„±

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img88.png){: width="" height=""}

    lossë¥¼ êµ¬í•´ì„œ Ground truthë¥¼ ë”°ë¼í•˜ë„ë¡ í•™ìŠµ

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img89.png){: width="" height=""}

    Attended visual feature ì„ ë½‘ì•„ë‚´ê³  soundì™€ unsupervised metric learn

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img90.png){: width="" height=""}

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img91.png){: width="" height=""}  


  - Cocktail party  
  Speech saparation by Visual

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img92.png){: width="" height=""}  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img93.png){: width="" height=""}  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img94.png){: width="" height=""}  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img95.png){: width="" height=""}  

  Training Dataê°€ ì›ë˜ë¶€í„° ë¶„ë¦¬ë˜ì–´ ìˆì„ ìˆ˜ê°€ ì—†ë‹¤. ê·¸ë˜ì„œ syntheticallyí•˜ê²Œ Clean Speechë¥¼ 2ê°œ concatí•´ì„œ ì‚¬ìš©í•œë‹¤.  

  - Lip movements Generation (Obama)

  - Tesla self-driving

## 2. ê³ ë¯¼ ë‚´ìš©, ê²°ê³¼ (ê³¼ì œ ìˆ˜í–‰ ê³¼ì •, ê²°ê³¼ë¬¼ ì •ë¦¬)

### ê³¼ì œ

## 3. í”¼ì–´ì„¸ì…˜ ì •ë¦¬

[ 2021ë…„ 9ì›”16ì¼  ëª©ìš”ì¼ íšŒì˜ë¡ ]

âœ… ì˜¤ëŠ˜ì˜ í”¼ì–´ì„¸ì…˜ (ëª¨ë”ë ˆì´í„°: ë°±ì¢…ì›)

1. ê°•ì˜ ìš”ì•½
    - ë°œí‘œì: ë°±ì¢…ì›
    - ë‚´ìš© : Multi-modal Learning

ğŸ“¢Â í† ì˜ ë‚´ìš©

1. í•„ìˆ˜ê³¼ì œ 4ë²ˆ ê´€ë ¨ ì—ëŸ¬
2. GAN Implements : [https://github.com/eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN) (ê³µìœ : ì¡°ì¤€í¬ ìº í¼ë‹˜)

ğŸ“¢ ë‚´ì¼ ê°ì í•´ì˜¬ ê²ƒ

1. ëª¨ë”ë ˆì´í„°: ì´ì–‘ì¬  ìº í¼ë‹˜

ğŸ“¢ ë©˜í† ë§ ì§ˆë¬¸ ì‚¬í•­

## 4. í•™ìŠµ íšŒê³ 

- ìƒê°ë³´ë‹¤ ì–‘ì´ ë§ê³  ì–´ë ¤ì› ë˜ ê²Œ ë§ì•˜ë˜ ê³¼ì •ì´ë‹¤. ê·¸ëŸ°ë° ì‹œê°í™”ê°€ ì•„ë‹Œ sound ë“±ì„ í•¨ê»˜ ì´ìš©í•  ìˆ˜ ìˆëŠ” multi-modal learningì— ëŒ€í•´ í¥ë¯¸ê°€ ë§ì´ ìƒê²¼ë˜ ê°•ì˜ì˜€ë‹¤.  