---
title: "[네이버 부스트 캠프] AI-Tech - Lv2 week8(3)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 57

## 1. 강의 복습 **내용**

#### 1.1 HRNet의 필요성

HRNet의 경우, 성능적인 측면에서 좋습니다. Cityscape 대회에서도 충분히 우수한 성적을 보였고, 현재 여러 연구 분야에서도 HRNet을 기반으로 upgrade하는 모델들을 많이 연구하기 시작했습니다.  

이번에는 이 중에서 Deep High-Resolution Representation Learning for Visual Recognition (HRNetv2) 를 살펴보려 합니다.  

  ![tmp](/assets/images/AI-Images2/lv2_week12_3/img1.png)

Image Classification Networks의 발전의 시작 : LeNet  
다음과 같이 고해상도 이미지로부터 conv & pooling 연산을 반복하며 저해상도 feature을 생성했습니다.  

  ![tmp](/assets/images/AI-Images2/lv2_week12_3/img2.png)

LeNet 이후 개발된 이미지 분류 모델은 다음과 같이 연대기를 거쳐왔습니다.  

  ![tmp](/assets/images/AI-Images2/lv2_week12_3/img3.png)

위와 같은 Network들은 공통적으로 고해상도 입력을 점차 저해상도로 줄여나가는 설계 방식을 이용했습니다.  
Segmentation 연구에서는 Image-classification backbone을 기준으로 저해상도 high-level feature를 이용해서 segmentation 결과를 생성했습니다.  

  ![tmp](/assets/images/AI-Images2/lv2_week12_3/img4.png)

여기서 Image Classification 모델의 해상도를 줄여가는 이유?
  - 특정 물체를 분류하는데 이미지 내 모든 특징이 필요하지 않음
  - 해상도가 줄어 효율적인 연산 가능, 넓은 receptive field를 갖게 됨
  - 중요한 특징만을 추출 (by maxpooling) 하여 overfitting 방지  

Image classification vs Semantic Segmentation (차이점)  
  - 이미지 분류 모델은 공간적 정보 고려 x,  
    Segmentation은 예측하려는 각 픽셀 주변의 context 파악을 위한 공간 상의 위치 정보가 중요  
  - 중요 특징을 추출하기 위해 수행하는 pooling 등의 연산은,  
    모든 픽셀에 대해 정확히 분류하기에 자세한 정보를 유지하지 못함.  
  - **즉, Segmentation에서는 더 높은 해상도를 유지해서 자세한 정보를 유지할 필요가 있습니다.**

<br>

Revisit : DeconvNet, SegNet, U-Net  
  - 저해상도 특징을 생성하고, 다시 고해상도로 복원하는 방식의 기존 연구입니다.  

      ![tmp](/assets/images/AI-Images2/lv2_week12_3/img5.png)

    U-Net의 경우 down-sampling 과정을 진행한 후, 다시 Upsampling을 하면서 이전 feature map을 crop하게 되는데 여기서 고해상도로 복원하는 과정은 **Sparse한 feature map을 생성한다는 문제점**을 가지고 있습니다.  

Revisit : DilatedNet, DeepLab  
  - DeepLab의 경우, 위에 나타난 Sparse feature map의 문제점을 막기 위해서 **dilated convolution을 사용해서 Dense feature map을 추출**하도록 했습니다.  
  
      ![tmp](/assets/images/AI-Images2/lv2_week12_3/img6.png)

  - DilatedNet 및 DeepLab 구조는 해상도의 이점을 위해 dilated conv를 이용했습니다.
  - 저해상도가 아닌 중해상도 (1/8만큼) 정보를 고해상도로 복원했습니다.
  - 둘의 차이점은 Deconv (Transposed Convolution) 와 Bi-linear interpolation의 차이가 있습니다.

      ![tmp](/assets/images/AI-Images2/lv2_week12_3/img7.png)

Revisit : DeepLab v3+  
  - Encoder-Decoder의 장점과 dilated conv의 장점을 모두 가져온 구조입니다.  
  - 자세한 정보를 유지하기 위해서 Xception 구조 내 max-pooling 연산을 depthwise separable conv (stride2) 로 변경했습니다.  

      ![tmp](/assets/images/AI-Images2/lv2_week12_3/img8.png)

  - 기존의 Encoder-Decoder 구조처럼 low-level feature를 이용해서 skip-connection을 하는 것 또한 적용 -> down-sampling 과정에서 잃어버린 정보를 복원해주는 것과 같은 역할을 해준다.  

      ![tmp](/assets/images/AI-Images2/lv2_week12_3/img9.png)

Revisit : Previous Segmentation Networks (위의 내용 정리)  
  - DeconvNet, SegNet, U-Net
    - 여러 번의 **pooling 연산**을 통한 저해상도 정보를 활용

  - DilatedNet, DeepLab
    - **Dilated Convolution** 적용 or pooling 연산을 제거해서 중해상도 정보를 활용

Revisit : Classification based Networks (backbone)

Deconvnet - vgg16  
segnet - vgg16 + full connected layer 제거  
DilatedNet, DeepLabv1 - Network 수정 -> Maxpooling 연산 제거 or 연산 변경 (stride, padding 조절)  
Deeplabv3++ - modified xception + stride2 conv -> stride1 conv (해상도 변화 x )  

  - 문제점 1) 기존 classification Network 사용에 필요했던 높은 time complexity
  - 문제점 2) Upsampling을 이용해 저해상도 -> 고해상도로 복원했을 때, 위치정보의 민감도가 낮다.  

  **-> 위의 문제들을 해결하기 위해서 강력한 위치 정보를 갖는 visual recognition 문제에 적합한 구조가 필요**

  결국엔 저/중해상도 -> 고해상도 복원이 아닌 고해상도를 계속 유지하는 Network를 만들기 위해 고안해낸 방법이 HRNet (High Resolution Network) 입니다.  
  HRNet 같은 경우, image classification에서 사용하는 backbone network가 아닌 위치 정보가 중요한 visual recognition 문제에 사용할 수 있는 **새로운 backbone network** 입니다.  

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img10.png)

### 2. HRNet 구조

#### 2.1 HRNet의 구성 요소

HRNet (High Resolution Network)  

- 구성요소 1. 전체 과정에서 고해상도 특징을 계속 유지
  - 입력 이미지를 그대로 이용하는 것이 아닌 Strided Convolution을 이용해 해상도를 1/4로 줄임 -> 계속 유지

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img11.png)

  - 1/4로 만드는 것은 1/2씩 strided Convolution을 이용해서 resolution을 맞춰줍니다.  

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img12.png)

  - 왜 High Resolution 이라고 하는 것일까?  
    다른 모델에 비해 고해상도를 계속 유지하고 있는 것 (U-Net : 1/20, DeepLab v3+ : 1/16)

#### 2.2 다중 해상도 정보 생성 및 병렬 처리

- 구성요소 2. 고해상도 ~ 저해상도까지 다양한 해상도를 갖는 특징을 병렬적으로 연산  
  - 기존의 경우, Receptive field를 넓히거나 연산의 효율을 위해서 Image의 크기를 줄였습니다.  
  그렇게 된다면 고해상도를 유지하기 위해서는 많은 연산량이 필요하고 receptive field 또한 작았을 것입니다.  
  - 다양한 해상도의 병렬화를 통해 Receptive field의 문제에 대해서 해결하려고 시도했습니다.  
    저해상도는 차원을 크게, 고해상도는 차원을 작게 만들어서 효율적인 연산을 고안해냈습니다.

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img13.png)

  - 아래와 같이 새로운 stream이 생성될 때마다 이전 단계 해상도의 1/2로 감소합니다.  
  이를 통해, 넓은 receptive field를 갖는 특징을 고해상도 특징과 함께 학습합니다.  

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img14.png)

#### 2.3 다중 해상도 정보의 반복적 융합

- 구성요소 3. 다중 해상도 정보를 반복적으로 융합  
  - 각각의 해상도가 갖는 정보를 다른 해상도 stream에 전달하여 정보를 융합
    - 고해상도 : 공간 상의 높은 위치 정보 민감도
    - 저해상도 : 넓은 receptive field로 인해 상대적으로 풍부한 semantic information을 가짐 (조금 더 detail한 information을 가진다.)

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img15.png)

  - 고해상도 -> 저해상도 : Strided Conv (정보 손실 최소)
    저해상도 -> 고해상도 : Bilinear Upsampling + 1x1 Conv (Time Complexity & 채널 수)

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img16.png)

#### 2.4 다양한 종류의 출력 생성

  ![tmp](/assets/images/AI-Images2/lv2_week12_3/img17.png)

- HRNetV1 : 저해상도를 제외한 고해상도 특징만을 최종 출력으로 사용 (ex. Pose Estimation)

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img18.png)

- HRNetV2 : 저해상도 특징들을 bilinear upsampling을 통해 고해상도 크기로 변환 후 모든 특징들을 합하여 출력 (ex. Semantic Segmentation)

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img19.png)

- HRNetV2p : HRNetV2의 결과에서 추가로 down sampling한 결과 출력, Faster-RCNN등의 backbone으로 사용 (ex. object detection)  

    ![tmp](/assets/images/AI-Images2/lv2_week12_3/img20.png)

#### 2.5 정리

HRNet for Semantic Segmentation

1) 입력 이미지는 1/4 해상도를 가짐
2) 1/4 해상도 유지 + 새로운 저해상도 생성 및 서로의 정보 융합
3) 모든 해상도 정보를 합한 후, 각 해상도를 representation head 내에서 bilinear upsampling 진행, Concat 후, Segmentation Head를 통과해서 Segmentation 수행  

  ![tmp](/assets/images/AI-Images2/lv2_week12_3/img21.png)

### 3. HRNet의 세부 구조 및 구현



## 2. 고민 내용, 결과 (과제 수행 과정, 결과물 정리)

### 프로젝트 수행

## 3. 피어세션 정리

### 피어세션

## 4. 학습 회고
