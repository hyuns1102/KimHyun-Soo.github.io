---
title: "[ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ ìº í”„] AI-Tech - Lv2 week2(3)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## í•™ìŠµê¸°ë¡ - 33

ì˜¤ëŠ˜ í•  ì¼

- Multi-modal Learning

## 1. ê°•ì˜ ë³µìŠµ ë‚´ìš©

### Multi-modal Learning

í•œ íƒ€ì…ì— ë°ì´í„°ê°€ ì•„ë‹Œ ë‹¤ë¥¸ íŠ¹ì„±ì˜ ë°ì´í„°ë„ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²ƒ (ì†Œë¦¬, ë§›, ëŠë‚Œ..)

multi-modal learning  
ì—¬ëŸ¬ê°€ì§€ ê°ê° ë°ì´í„°ë¥¼ 'í•¨ê»˜' ì‚¬ìš©í•˜ëŠ” ê²ƒ. ì‚¬ëŒì€ ì¼ë°˜ì ìœ¼ë¡œ multi-modal í˜•íƒœë¡œ ì‚¬ë¬¼ì„ ì¸ì§€í•œë‹¤. (<-> unimodal (í•œê°€ì§€ë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒ))  

- ë¬¸ì œì   

  - ë‹¤ë¥¸ ë°ì´í„° êµ¬ì¡°  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img52.png){: width="200px" height="200px"}  

  - featureì˜ Unbalance matching  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img53.png){: width="200px" height="200px"}  

  - Specific dataì— ë” biasedí•œ í˜•íƒœë¡œ trainig  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img54.png){: width="200px" height="200px"}  

  - ë¬¸ì œì ì´ ìˆìŒì—ë„ ë‹¤ì–‘í•œ ë°©ë²•ì„ í†µí•´ ìœ ìµí•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img55.png){: width="" height=""}  

- Text embedding  

  word embeddingì„ í†µí•´ì„œ ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ 'ë‹¨ì–´'ë“¤ì— ëŒ€í•´ ì¼ë°˜í™”ê°€ ê°€ëŠ¥í•˜ë‹¤.
    ![Untitled](/assets/images/AI-Images2/lv2_week2/img56.png){: width="200px" height="200px"}  

  - Skip-gram model

    input layer -> hidden layer  
    input layerì— ìˆëŠ” vectorëŠ” ì–´ë–¤ ë‹¨ì–´ë“¤ì˜ ë²¡í„°ì´ê³  ë‹¨ì–´ê°€ Wì— ì˜í•´ hidden layerë¡œ ëœë‹¤. ì–´ë–¤ ë‹¨ì–´ì— ëŒ€í•œ íŠ¹ì§•ì„ ì¶”ì¶œí•œë‹¤.  
    hidden layer -> output layer  
    ë‹¨ì–´ ì „ í›„ì˜ ì–´ë–¤ ë‹¨ì–´ê°€ ì˜¤ëŠëƒì— ë”°ë¼ output layerì˜ feature ê²°ì •í•´ì„œ í•™ìŠµí•œë‹¤.  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img57.png){: width="" height=""}

    Skip-gram modelì€ neighboring N wordsì— ëŒ€í•´ì„œ í•™ìŠµí•´ì„œ ì£¼ë³€ ë‹¨ì–´ë“¤ê³¼ì˜ 'ê´€ê³„'ì— ëŒ€í•´ í•™ìŠµí•œë‹¤.  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img58.png){: width="" height=""}

- Joint embedding (Matching)  
  Image tagging  
  Image -> tag or tag -> Image  

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img59.png){: width="" height=""}

  Joint embeddingì—ì„œëŠ” ê° Dataì˜ featureë¥¼ ì¶”ì¶œí•œ í›„, ê°™ì€ dimensionìœ¼ë¡œ ë§Œë“  outputì˜ ê±°ë¦¬ì— ë”°ë¥¸ ìƒê´€ì„±ì„ ë‚˜íƒ€ë‚¸ë‹¤.  
  ì´ë ‡ê²Œ matchingì˜ ì •ë„ì— ë”°ë¼ ë°€ê³  (push) ë‹¹ê¸°ëŠ” (pull) í•™ìŠµì„ **metric learning** ì´ë¼ê³  í•œë‹¤.

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img60.png){: width="" height=""}

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img61.png){: width="" height=""}

  - Image tagging - interesting property
    dog Image - 'dog' + 'cat' -> cat Image + dog Image's background  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img62.png){: width="" height=""}

  - Image tagging - food Image vs recipe text
    recipeê³¼ Imageì˜ jointë¥¼ í†µí•´ cosine simmilarity loss ì™€ semantic regularization lossë¥¼ ë§Œë“ ë‹¤.  
    cosine simmilarity lossëŠ” Imageì™€ recipeì˜ ìƒê´€ì„±,  
    semantic regularization lossëŠ” cosine simmilarity lossë¡œ í•´ê²°ì´ ì•ˆë˜ëŠ” ë¶€ë¶„ì— ëŒ€í•´ ê°€ì´ë“œë¥¼ ì¤€ë‹¤. (high-level semantic)

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img63.png){: width="" height=""}

- Cross modal translation (Translating)  

  - Image captioning
    Imageê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì´ë¯¸ì§€ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì¥ ì¶œë ¥

    - show and tell  
      Encoder : CNN modelì„ í†µí•´ì„œ feature ì¶”ì¶œ  
      Decoder : Encoderì—ì„œ ì¶”ì¶œí•œ featureë¥¼ conditionìœ¼ë¡œ í•˜ëŠ” LSTM moduleë‚´ì— RNNì„ í†µí•´ ë‹¨ì–´ ì¶”ì¶œ -> sentence

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img64.png){: width="" height=""}

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img65.png){: width="" height=""}

    - show, attend and tell
      Image ë‚´ì— íŠ¹ì • ì˜ì—­ì„ í™•ì¸í•˜ê³  ì•Œë§ëŠ” sentence ì¶œë ¥  
      Imageì—ì„œ CNNì„ í†µí•´ì„œ convolutional feature ì¶”ì¶œ, RNNì—ì„œ attend ëœ ë¶€ë¶„ì— word generation  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img66.png){: width="" height=""}

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img67.png){: width="" height=""}

    - show, attend and tell (soft attention)  
      attentionì€ ì¸ê°„ì´ ì‚¬ë¬¼ì„ ë³¼ ë•Œ ë³´ëŠ” ë°©ë²•ê³¼ ì¼ì¹˜í•˜ë‹¤. ì¸ê°„ì´ ë³´ëŠ” ë°©ë²•ê³¼ ë¹„ìŠ·í•˜ê²Œ í•˜ê¸° ìœ„í•´ Imageì˜ íŠ¹ì§•ì ì¸ ë¶€ë¶„ì„ ë”°ì„œ ì£¼ìš” ë¶€ë¶„ë§Œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.  

      Imageë¥¼ CNNì— ë„£ì–´ feature vectorë¥¼ gridë¡œ ë‚˜íƒ€ë‚´ê³  ê° featureì— ëŒ€í•´ì„œ RNNì„ í†µê³¼ì‹œì¼œì„œ ì–´ë””ë¥¼ referenceë¥¼ ì¤˜ì•¼í•˜ëŠ” ì§€ heat mapìœ¼ë¡œ ë‚˜íƒ€ë‚´ì¤€ë‹¤.  
      feature vectorì™€ heat mapì—ì„œ feature ë“¤ì˜ probablityë¥¼ weighted sum í•´ì¤˜ì„œ zë¡œ ë‚˜íƒ€ë‚¸ë‹¤.  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img68.png){: width="" height=""}

      ìœ„ì˜ ë‚´ìš©ì„ ë” ìì„¸í•œ ê³¼ì •ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´,  
      Imageë¥¼ CNNìœ¼ë¡œ í†µê³¼í•´ì„œ feature vectorë¥¼ ë‚˜íƒ€ë‚´ì¤€ë‹¤. ì´ê²ƒì„ LSTMì˜ conditionìœ¼ë¡œ ë„£ì–´ì¤€ë‹¤. (h0) LSTMì—ì„œ ì–´ë”” ë¶€ë¶„ì€ attention í•  ì§€ spatial attentionì„ weightë¡œ ì¶œë ¥ í•´ì¤€ë‹¤. (s1)  
      ì´ weightë¥¼ ì´ìš©í•´ì„œ features ì™€ inner productë¥¼ í•´ì¤ë‹ˆë‹¤. (s1, features -> z1)  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img69.png){: width="" height=""}  

      ì—¬ê¸°ì„œ z1ì„ ë‹¤ìŒ RNN step (LSTM) ì— conditionìœ¼ë¡œ ë„£ì–´ì£¼ê²Œ ë˜ê³ , start word tokenì„ ë„£ì–´ì¤€ë‹¤. (h1) h1ì—ì„œ conditionì„ ë³´ê³  ì–´ë–¤ ë‹¨ì–´ë¡œ ì‹œì‘í•´ì•¼í•  ì§€ ê³ ë¯¼ì„ í•˜ê³  wordë¥¼ ì¶”ì¶œ í•œë‹¤. (d1) ë™ì‹œì—, ì–´ë””ë¥¼ reference í•  ê²ƒì¸ì§€ Imageë¥¼ ì¶”ì¶œí•´ì¤€ë‹¤.(s2)  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img70.png){: width="" height=""}  

      ì´ì „ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ featureì™€ weightë¥¼ inner productí•´ì„œ z2ë¥¼ ë§Œë“¤ì–´ì£¼ê³ , LSTMì— ë„£ì–´ì¤€ë‹¤.  
      ì´ ë•Œ tokenì€ ì´ì „ì— ì¶œë ¥í–ˆë˜ ë‹¨ì–´ë¥¼ ë„£ì–´ì¤€ë‹¤.  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img71.png){: width="" height=""}  

      ì´ì „ì— í–ˆë˜ ë°©ì‹ì„ ë°˜ë³µí•˜ë©´ sentenceë¥¼ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆë‹¤.  

        ![Untitled](/assets/images/AI-Images2/lv2_week2/img72.png){: width="" height=""}  

  - Text-to-Image
    ì´ë²ˆì—” ì•„ê¹Œí–ˆë˜ ê²ƒê³¼ ë°˜ëŒ€ë¡œ textë¥¼ ì¸ì‹í•˜ê³  Imageë¥¼ outputìœ¼ë¡œ í•˜ëŠ” ë°©ë²•ì´ë‹¤. Generative model (cGAN) ì„ ì´ìš©í•´ì„œ í•™ìŠµì„ ì§„í–‰í•œë‹¤.  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img74.png){: width="" height=""}  

    ë¨¼ì € sentence (condition) ë¥¼ pre-trained networkì— ë„£ì–´ fixed-dimensional vectorë¥¼ ë§Œë“ ë‹¤. ì—¬ê¸°ì— Gaussian Random Code vectorë¥¼ ë¶™ì—¬ì„œ (z~N(0,1)) Networkì— ë„£ì–´ decoderì—ì„œ Imageë¥¼ ì¶œë ¥í•´ì¤€ë‹¤.  
    ì´ ë•Œ, Gaussian Random codeëŠ” ê²°ê³¼ê°€ ë” diverseí•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.  

    ì—¬ê¸°ì„œ ì¶œë ¥ëœ Imageë¥¼ low-dimensionalë¡œ ë§Œë“¤ì–´ì„œ ì´ì „ sentence (condition) ì„ ë„£ì–´ True or Falseë¥¼ ê²°ì •í•œë‹¤.  

      ![Untitled](/assets/images/AI-Images2/lv2_week2/img73.png){: width="" height=""}

    ì´ì „ì— í–ˆë˜ cGANì˜ architecturì™€ ë§¤ìš° ë¹„ìŠ·í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.  

- Cross modal reasoning (Referencing)  







## 2. ê³ ë¯¼ ë‚´ìš©, ê²°ê³¼ (ê³¼ì œ ìˆ˜í–‰ ê³¼ì •, ê²°ê³¼ë¬¼ ì •ë¦¬)

### ê³¼ì œ

## 3. í”¼ì–´ì„¸ì…˜ ì •ë¦¬

[ 2021ë…„ 9ì›”15ì¼  ìˆ˜ìš”ì¼ íšŒì˜ë¡ ]

âœ… ì˜¤ëŠ˜ì˜ í”¼ì–´ì„¸ì…˜ (ëª¨ë”ë ˆì´í„°: ê¹€í˜„ìˆ˜)

1. ê°•ì˜ ìš”ì•½
    - ë°œí‘œì: ê¹€í˜„ìˆ˜
    - ë‚´ìš© : Conditional Generative Model

ğŸ“¢Â í† ì˜ ë‚´ìš©

1. Pix2Pix loss ì˜ GAN loss ì—ì„œ x, y?

    ![Untitled](/assets/images/AI-Images2/lv2_week2/img51.png)

2. cGANì—ì„œ L1 Lossë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ?
3. Super Resolution - HR (ì›ë³¸) ì´ë¯¸ì§€ì™€ LR (down sampling) ì´ë¯¸ì§€ë¥¼ cGANì— í•™ìŠµì‹œì¼œ super resolution ê°€ëŠ¥í•˜ë„ë¡ í•œë‹¤. 
4. Gram matrices ë§Œë“¤ ë•Œ feature map channel ì¶•ìœ¼ë¡œ reshape í•œ vector ì™€ ê·¸ vector ë¥¼ transpose í•´ì„œ ê³±í•œ í›„, C x C ë¡œ ë§Œë“¤ì–´ ì‚¬ìš©í•œë‹¤.
5. ë©˜í† ë§ ì‹œê°„ 9/17(ê¸ˆ) 4:30pm  & ê¸ˆìš”ì¼ í”¼ì–´ì„¸ì…˜ ì‹œê°„ 4:00 pmì— íŒ€íšŒê³  ë° ê°•ì˜ ë¦¬ë·°

ğŸ“¢ ë‚´ì¼ ê°ì í•´ì˜¬ ê²ƒ

1. ëª¨ë”ë ˆì´í„°: ë°±ì¢…ì› ìº í¼ë‹˜

## 4. í•™ìŠµ íšŒê³ 

í•  ì¼ì€ ë§ì€ë° ì‹œì‘ í•˜ê¸°ê°€ ë‘ë ¤ìš´ ë§¤ì¼.. ê±±ì •ì€ ë§ì€ë° ì œëŒ€ë¡œ ëœ ê²Œ ì—†ë‹¤.
