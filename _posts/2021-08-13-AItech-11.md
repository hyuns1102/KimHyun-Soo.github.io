---
title: "[네이버 부스트 캠프] AI-Tech-re - week2(5)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 9

오늘 한 일

- 필수 과제 MHA
- Generative 1, 2
- Computer Visualization
- Data Viz

### 1. 강의 복습 내용

#### Generative Models

생성 모델

- 분류 문제는 크게 Generative Model (Unsupervised) 과 Discriminative model (Supervised) 로 나눠진다.

  - Discriminative model의 경우, 우리가 이전에 했던 회귀 분석처럼 클래스를 나눠서 확률을 통해 분류를 한다.
  - Generative model의 경우, likelihood 나 사후확률 (posterior probability)를 사용해서 분류 경계선(decision boundary)를 만든다.

  - Generative model은 단순히 생성 모델이 아닌  확률을 나타내는 explicit model도 있다.  
  그렇다면 그 p(x)를 어떻게 나타낼 것인가?

- RGB 모델의 경우, 한 픽셀을 나타내기 위한 Parameter의 개수는 (256 X 256 X 256 - 1) 로 나타낼 수 있다.  
R,g,b는 서로 independent / category distribution 에 의해 -1을 해야 한다.  
Binary 의 경우 2^n - 1

2^n -> n 으로 바뀌는데  
질문) 왜? 독립이면 State는 그대로인데 parameter는 왜 그런 것이지?

- Chain rule & Bayes' rule & conditional independence 를 잘 활용해서, fully dependent model and fully independent model 사이에 좋은 모델을 만드는 것이 목표 ( Parameter 의 개수 줄이기 )

- Conditional Independence - Markov Assumption
직전까지만 dependent 하고 이전 모든 값들은 independent하다고 가정한다면?
-> Auto regressive model

- Auto regressive model
직전 뿐만 아니라 더 길게 잡아도 이 모델에 적용된다. 순서에 따라 성능 차이가 달라진다.  

![s1](/assets/images/AI-Images/img60.png)

- NADE : Neural Autoregressive Density Estimator
Explicit model : 확률 분포 계산
Implicit model : Generation

![s2](/assets/images/AI-Images/img61.png)
![s3](/assets/images/AI-Images/img62.png)

- Pixel RNN
Auto regressive model
RNN을 통해 만들어 내겠다.

#### Generative Models - 2

- Latent Variable Models

Autoencoder은 generative model인가?
그렇지 않다. Variation Autoencoder가 generative model이 될 수 있다?

Variational inference(VI)

- 목적 ? Posterior distribution에 가장 잘 맞는 variational distribution을 최적화 하는 것

- 무언가를 잘 최적화하겠다? KL divergence를 이용해서 PD 와 VD를 줄여보겠다.

Variational Auto-encoder

 how?
  ELBO  
  AAE  
  GAN  
  에 대한 내용은 다시 공부를 하면서 알아봐야겠다.

#### Computer Visualization

- Semantic Segmentation

  - 어떤 이미지가 있을 때, 픽셀마다 분류하는 것 
  - 자율 주행에서 주로 이용

- Fully Convolutional Network

  - Dense layer를 없애고 싶은 것.

  ![s3](/assets/images/AI-Images/img63.png)

  Parameter는 같은데 왜 하는 것일까?
  Input 이미지에 상관없이 단순히 분류가 아닌 heat map이 나올 수 있도록 한다.

  - upsampling 방법
  Deconvolution : Convolution의 역연산
  Padding을 많이 줘서 할 수 있도록 한다. 

  ![s3](/assets/images/AI-Images/img64.png)

- Detection

  - R-CNN : Bounding Box를 찾는 것
    Image 안에서 바운드리를 친 다음에 각각 분류를 시작한다.

  - SPPNet : R-CNN은 Image안에서 2000개의 바운딩 박스를 뽑으면 비효율적.  
    Image 내에서 Convolution 으로 feature 생성 후 바운딩된 부분 Tensor을 뽑아내자  

    ![s4](/assets/images/AI-Images/img65.png)


  - Fast R - CNN
  이미지 내에서 feature map을 뽑아낸 뒤, 각 영역마다 ROI  feature을 뽑는다. 그 이후 바운딩 박스를 분류함.

  - Faster R - CNN
  바운딩 박스를 뽑는 것도 네트워크를 학습하자.  -> Region Proposal Network

  - Region Proposal Network
    어떤 영역안에 이 물체가 있을 것 같다?
    Template을 미리 고정

    ![s4](/assets/images/AI-Images/img66.png)

    여기서도 fully conv 가 적용된다.

  - YOLO
  바운딩 박스를 따로 뽑는 것이 아닌 한번에 다 뽑는다.
  바운딩 + 클래스 찾기를 같이 한다.

### 2. 고민 내용, 결과 (과제 수행 과정, 결과물 정리)

1. 필수 과제 : MHA

    강의 따라 실습 진행, 다시 혼자 보면서 진행해봐야겠다.  
    코드에 대한 완벽한 이해는 아니었지만, 코드 실습을 통해 Self-attention에 대한 이해와 Multi Head attention에 대한 내용을 이해할 수 있었다.

### 3. 피어세션 정리

1. 스페셜 피어세션 : 다른 팀들과의 피어세션 주제 공유를 통해 다른 방향도 생각해보게 되었다. (논문 정리, 코드 리뷰)

2. Generative Model : 이론 리뷰

3. 팀 학습 회고

### 4. 학습 회고

1. 오늘 같은 경우, 어려운 부분이 너무 많았다.  
  일단 넘어가면서 강의를 듣긴 했는데 나중에 자세하게 보는 일정이 필요한 것 같았다.  
  아무래도 이렇게해서는 계속 미뤄질 것 같다.  
  하루 일정은 하루 안에 끝내는 것을 목표로 해야할 것 같다.  