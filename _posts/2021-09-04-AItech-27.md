---
title: "[네이버 부스트 캠프] AI-Tech - week5(4)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 25

1. 개인 학습 :  

    목표 : 마스크 모델의 실제 성능을 올리는 것
    내가 한 노력 : 본래 마스크 모델에서는 직접 모델을 돌렸을 때, valid f1 기준으로 약 99%   가까이 되는 성능을 보여줬으나 실제 test set에서는 성능이 그렇게 좋지 못했다. 이유는   overfitting 이라고 생각했기에, 데이터를 조금 더 일반화 시켜주기 위한 시도를 했다.  

    캐글에서 가져온 데이터를 이용해서 Mask, not wear, incorrect Mask를 넣어 실험을 진행했다.
    데이터의 수집과 정리 과정은 코드를 짰다. 최대한 basic data의 표와 맞출 수 있도록 data와     csv파일을 만들었다. 또한, 각각 image 사이즈가 난잡했기에 Resize와 Crop을 이용해서 새롭게    image를 저장했다.  

    처음으로, 데이터 비율 ( wear, not wear, incorrect = 5000, 5000, 700) 을 넣었을 때,  실험을 진행했다. valid f1 이 전반적으로 이전에 진행했던 normal data에 비해서 평가    데이터의 정확도가 살짝 오른 것을 볼 수 있었다.  

    하지만 이렇게 진행을 해도 실제 리더보드에 제출했을 때는 좋지 않은 결과를 받았다. 또한,  아직까지 incorrect data에 대한 구분이 명확하지 않았다는 것을 알았고, incorrect의 비율을  높이기 위해 데이터를 조금 더 수집했다. incorrect한 부분을 찾기가 쉽지 않았고, 직접   이미지 데이터를 더 추가하거나 찾아붙였다. 많은 성능이 오르지는 않았지만 약 0.005 정도의   f1 score가 올랐다. 하지만, 여전히 실제 테스트에서는 크게 성능을 올리진 못했다.  

    멘토링을 받아서 어느 정도 실제 test와 valid의 비율을 맞추고자 train, test split을   이용한 모델로 똑같이 학습을 진행했으나 큰 변화는 없었다. 또한, retina face를 이용해서     마스크 모델을 분류했을 때, 또한, f1 score는 비슷했으나, 실제 리더보드에서 좋은 결과를   얻을 수 있었다.  

    pseudo labeling을 이용한 모델 또한, 위와 같이 테스트할 때의 f1 score는 좋았으나, 실제   테스트에서 눈에 띄는 변화는 없다.  

    결론으로, croping을 통해 약간의 성능 변화는 얻을 수 있었다. 그리고 마스크 모델에서  valid를 통한 테스트는 실제 모델에서 측정하는 성능과 많이 상이했다. 또한, 데이터의    수집으로 인해 overfitting을 막을 수 있다고 생각했으나 모델 자체가 마스크의 쓰고 안쓰고를   잘 분류했다. 하지만 incorrect한 부분은 retina face를 이용해서 어느 정도 커버를 할 수  있었다고 생각했다.  

    아쉬웠던 점은 더 많은 기술적인 도전을 해보지 못한 것과 EDA를 통해 데이터가 잘못된 점을  제대로 찾지 못했다는 것이 아쉬웠다. 항상 data가 올바를 수만은 없고, EDA 과정을 거쳐 어느 정도 수정이 필요하다는 것을 느꼈다.  

2. 공동 학습 :

    먼저 팀으로 이루어졌을 때,  

    데이터 : 18 class 분류
    모델 : Resnet 18
    Loss : CrossEntropy
    Optim : ADAM
    transform : CenterCrop (300)
    -> Accuracy는 76.8%, f1-score는 0.71 정도로 측정.

    여기서 f1 score를 높이고자, 데이터의 특징을 분석했다.

    1. 60대 나이의 사람들이 너무 부족했다.
    2. 마스크만이 아닌 나이, 성별까지 신경써야 한다.
    3. 전체적으로 데이터가 부족하다.

    이 3가지 문제를 해결하고자 역할을 분담해서 데이터, 모델팀으로 나눠 일을 진행했다. 데이터   팀은 부족한 데이터를 해결하고자 public 데이터를 수집했고, 모델 팀은 나이, 성별을  고려해서 3가지 모델로 나눠 각각 학습할 수 있도록 코드를 수정했다.

    데이터 팀의 경우, 여러 데이터를 수집해서 좋은 데이터들을 분류하고 이용할 수 있도록 기존 데이터에 concat하고 데이터가 조금 더 학습을 잘할 수 있도록 cutmix, Augmentation, Albumentation을 이용하여 학습을 시도했다.  

    모델 팀의 경우, 다양한 모델을 시도하는 것과 동시에 hyper parameter들을 조정하면서 모델의 성능을 올릴 수 있도록 했다. 또한, Loss, valid의 비율 수정 등 효과적으로 결과를 뽑아낼 수 있도록 노력했다.  

    결과적으로, 78%의 Accuracy 와 0.731의 F1으로 약간의 성능 변화를 얻을 수 있었다. 

## 느낀점

모델을 협업으로 함께 만들어 나가면서 결과는 크게 좋아지진 않았지만 많은 것을 얻었던 것 같다.  
첫번째로, Git이다.보통 혼자서 blog를 작성할 때나 만든 프로젝트를 올릴 때, 개인적으로 사용하는 게 아닌 팀으로 사용할 수 있는 기회가 되어서 좋았다.  두번째로, EDA의 중요성데이터를 직접 다뤄보면서 성능 변화의 민감하게 반응하는 것이 데이터라는 것을 알았다. 아무리 모델이 잘 짜여져도 데이터가 잘못되면, 학습이 계속 잘못되는 것을 알 수 있었다. 데이터를 정확히 바라보는 것이 중요하다는 것을 느꼈다.

## 개인 회고 글

활동 :

- P-Stage
- 이미지 분류 팀 프로젝트
  - 데이터 분석 및 추가 후, 학습 (Mask)
  - wandb 를 이용한 성능 분석
  - 모델 및 각종 hyper parameter 변경을 통한 성능 분석
- 마스터 클래스 (김태진 강사님) - 피드백 & 리뷰

회고 (개선사항)

- 팀으로 GIt을 이용해본 점이 아주 좋은 경험이었다. 계속 헷갈려서 branch만들 때 꺼려했지만, 직접 해보면서 최신버전의 코드를 받고 이용해보면서 익숙해질 수 있다는 점이 좋았다. 개선을 위한 git 공부보다는 다음 팀에서도 계속 쓰도록 유도하는게 좋다고 생각한다.
- 지난 번에 회고했던 문제 정의를 완벽하게 제대로 하지 못했던 같다. 팀원들과의 회의를 통해 점점 더 알게되었다. 하지만 혼자 문제를 제대로 이해하지 못해서 곤란했던 적이 많았던 것 같다. 뭔가 완벽히 모르면 계속 흘려듣게 되는 것 같다고 느껴졌다. → 흠.. 많이 듣고 침착하게 생각해봐야겠다..?
- 모델링 시도를 해보기로 했으나, 경현님의 코드를 토대로 많이 배웠던 것 같다. 아직 내것을 직접 만들어보진 못했으나, 베이스 코드와 경현님의 코드를 직접 보면서 더 내 것으로 만들어봐야겠다고 생각을 많이 했다. → 베이스 라인 코드 직접 작성해보기..
- EDA에 관련해서 중요성을 많이 느꼈다. 데이터셋이 항상 완벽하지 않고, 데이터의 문제가 있다는 것을 파악하는 게 제일 중요했다. 모델이 아무리 좋아도, 데이터가 이상하면 계속 성능이 좋아질 수 는 없다는 것을 알았다. → EDA를 통한 데이터의 신뢰도 파악하기, 데이터,, 인간지능이라도 제대로 해야한다. (마스터)
- 다양한 시도를 직접해보지 못했던 것이 후회된다. 직접 만들어보는 것이 아니라 그냥 하라는 대로 했다는 것,, 그게 뭔가 아쉬웠던 것 같다.. → 직접 만들어보자. 실패해도 괜찮다 !

7feautures 팀들 모두 고생하셨습니다 !다음 팀에서도 파이팅!!