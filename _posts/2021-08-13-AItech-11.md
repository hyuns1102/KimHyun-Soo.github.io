---
title: "[네이버 부스트 캠프] AI-Tech-re - week2(5)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 9

오늘 한 일

- 필수 과제 MHA
- Generative 1, 2
- Computer Visualization
- Data Viz

### 1. 강의 복습 내용

#### Generative Models

생성 모델

- 분류 문제는 크게 Generative Model (Unsupervised) 과 Discriminative model (Supervised) 로 나눠진다.

  - Discriminative model의 경우, 우리가 이전에 했던 회귀 분석처럼 클래스를 나눠서 확률을 통해 분류를 한다.

  - Generative model의 경우, likelihood 나 사후확률 (posterior probability)를 사용해서 분류 경계선(decision boundary)를 만든다.
    - 예제로 우리가 강아지 사진들이 있다고 가정한다면,
    - Generative model은 Image를 Generation 한다. (Sampling)
    - Generative model은 어떤 확률로 분류하는 explicit model을 포함한다. (단순한 생성은 implicit model)
    - Unsupervised Representation learning, 어떤 특징을 잡아내는 Feature Learning을 한다.

    그렇다면 그 p(x)를 어떻게 나타낼 것인가?

    - RGB 모델의 경우, 한 픽셀을 나타내기 위한 Parameter의 개수는 (256 X 256 X 256 - 1) 로 나타낼 수 있다.  
    Binary Image의 경우 2^n - 1 개의 파라미터로 나타낼 수 있다. 그렇다면, 모든 경우가 independent하다면, 파라미터의 개수는 n개로 나타낼 수 있다. (state는 그대로)

- **Chain rule & Bayes' rule & conditional independence 를 잘 활용해서, fully dependent model and fully independent model 사이에 좋은 모델을 만드는 것이 목표 ( Parameter 의 개수 줄이기 )**

- Conditional Independence - Markov Assumption
직전까지만 dependent 하고 이전 모든 값들은 independent하다고 가정한다면?
-> Auto regressive model

- Auto regressive model (자기 회귀 모델)
직전 뿐만 아니라 더 길게 잡아도 이 모델에 적용된다. 순서에 따라 성능 차이가 달라진다. 독립적일 때, sequence에서 어떤 단어는 이전 단어의 영향을 받는다. 만약 x1이 나올 확률이 p(x1)이라고 하면 그 다음 단어 x2가 나올 확률은 p(x2|x1)가 되고, x3가 나올 확률은 p(x3|x1,x2) 이다. x784가 나올 확률은 chain rule에 의해서 p(x784) = p(x784|x1,x2,x3,...,x783) = p(x1) X p(x2|x1) X p(x3|x1,x2,x3) ... 가 된다.
자기 회귀 모델은 이전에 있던 sequence가 Input이 되어서 output을 만들게 한다.

![s1](/assets/images/AI-Images/img60.png)

- NADE : Neural Autoregressive Density Estimator
Explicit model : 확률 분포 계산
Implicit model : Generation

![s2](/assets/images/AI-Images/img61.png)
![s3](/assets/images/AI-Images/img62.png)

- Pixel RNN
Auto regressive model
RNN을 통해 만들어 내겠다.

#### Generative Models - 2

- Latent Variable Models

Autoencoder은 generative model인가?
그렇지 않다. Variation Autoencoder가 generative model이 될 수 있다?

Variational inference(VI)

- 목적 ? Posterior distribution에 가장 잘 맞는 variational distribution을 최적화 하는 것

- 무언가를 잘 최적화하겠다? KL divergence를 이용해서 PD 와 VD를 줄여보겠다.

Variational Auto-encoder

 how?
  ELBO  
  AAE  
  GAN  
  에 대한 내용은 다시 공부를 하면서 알아봐야겠다.

#### Computer Visualization

- Semantic Segmentation

  - 어떤 이미지가 있을 때, 픽셀마다 분류하는 것 
  - 자율 주행에서 주로 이용

- Fully Convolutional Network

  - Dense layer를 없애고 싶은 것.

  ![s3](/assets/images/AI-Images/img63.png)

  Parameter는 같은데 왜 하는 것일까?
  Input 이미지에 상관없이 단순히 분류가 아닌 heat map이 나올 수 있도록 한다.

  - upsampling 방법
  Deconvolution : Convolution의 역연산
  Padding을 많이 줘서 할 수 있도록 한다. 

  ![s3](/assets/images/AI-Images/img64.png)

- Detection

  - R-CNN : Bounding Box를 찾는 것
    Image 안에서 바운드리를 친 다음에 각각 분류를 시작한다.

  - SPPNet : R-CNN은 Image안에서 2000개의 바운딩 박스를 뽑으면 비효율적.  
    Image 내에서 Convolution 으로 feature 생성 후 바운딩된 부분 Tensor을 뽑아내자  

    ![s4](/assets/images/AI-Images/img65.png)


  - Fast R - CNN
  이미지 내에서 feature map을 뽑아낸 뒤, 각 영역마다 ROI  feature을 뽑는다. 그 이후 바운딩 박스를 분류함.

  - Faster R - CNN
  바운딩 박스를 뽑는 것도 네트워크를 학습하자.  -> Region Proposal Network

  - Region Proposal Network
    어떤 영역안에 이 물체가 있을 것 같다?
    Template을 미리 고정

    ![s4](/assets/images/AI-Images/img66.png)

    여기서도 fully conv 가 적용된다.

  - YOLO
  바운딩 박스를 따로 뽑는 것이 아닌 한번에 다 뽑는다.
  바운딩 + 클래스 찾기를 같이 한다.

### 2. 고민 내용, 결과 (과제 수행 과정, 결과물 정리)

1. 필수 과제 : MHA

    강의 따라 실습 진행, 다시 혼자 보면서 진행해봐야겠다.  
    코드에 대한 완벽한 이해는 아니었지만, 코드 실습을 통해 Self-attention에 대한 이해와 Multi Head attention에 대한 내용을 이해할 수 있었다.

### 3. 피어세션 정리

1. 스페셜 피어세션 : 다른 팀들과의 피어세션 주제 공유를 통해 다른 방향도 생각해보게 되었다. (논문 정리, 코드 리뷰)

2. Generative Model : 이론 리뷰

3. 팀 학습 회고

### 4. 학습 회고

1. 오늘 같은 경우, 어려운 부분이 너무 많았다.  
  일단 넘어가면서 강의를 듣긴 했는데 나중에 자세하게 보는 일정이 필요한 것 같았다.  
  아무래도 이렇게해서는 계속 미뤄질 것 같다.  
  하루 일정은 하루 안에 끝내는 것을 목표로 해야할 것 같다.  