---
title: "[네이버 부스트 캠프] AI-Tech - Lv3 모델 경량화(2)"
categories: AI boostcourse
tags: python
published: trues
use_math: true
---

## 학습 기록

## 좋은 모델과 파라미터 찾기 : AutoML 이론

Conventional DL pipeline이 어떤 문제를 해결? 목적?
Configuration의 특성?, 경량화 관점에서 AutoML이 어떤 의미를 가지는지?
AutoML Pipeline 구현 & 한계점, 현실적인 접근?

### Overview

#### Conventional DL Training Pipeline

"Data Engineering"이라 하면,  
우리가 이전에 했듯이 데이터를 정제하고 전처리를 거친 후,  
Feature Engineering을 진행한 후에, (주어진 데이터로 예측 모델의 문제를 잘 표현하는 features로 변형시키는 과정)  
적합한 모델을 선정해서 (ML Algorithm) 적합한 Hyperparameters를 선정합니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img16.png)

위와 같은 Data Engineering을 거친 후, 적합한 모델의 Architecture와 Hyperparameter (좋은 Configuration) 를 위해서 Train & Evalutation을 반복하게 됩니다.  
여기서 이 과정은 사람이 끊임없이 반복하게 됩니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img17.png)

#### Objectives of AutoML

위와 같은 과정들은 고객의 요구사항에 의해 새로운 데이터가 들어오거나 또 다른 예측 output을 내고 싶다면, 새롭게 tuning을 하게 됩니다.  

여기서 사람들이 작업해야하는 과정을 빼내고자 하는 것이 **Automated Machine Learning(AutoML)** 의 목표입니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img18.png)

AutoML의 문제 정의  
HyperParmeter Sample에 대해서 Algorithm, Data Train, Data Valid가 정의되어 있을 때, Loss가 가장 낮은 Hyperparameter를 정의해주는 것  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img19.png)

#### Properties of configurations in DL

DL model Configuration (Architecture, Hyperparameter)의 특징

1. 주요 타입 구분

  - Categorical
    - ex) optim : (Adam, AdamW, SGD) module : (Conv, BottleNeck, Residual block, ..)
  - Continuous
    - ex) learning rate, regularizer param, ...
  - Integer
    - ex) batch_size, epochs, .. 

2. ⭐Conditional⭐한 Configuration에 따라 Search space가 달라질 수 있습니다.  

  - Optimizer의 sample(e.g.SGD,Adam등등)에 따라서 optimizer parameter의 종류, search space도 달라짐 (e.g, optimizer에 따른 learning rate range 차이, SGD:momentum, Adam:alpha,beta1,beta2,..등등)
  - Module의 sample (e.g.VanillaConv, BottleNeck, InvertedResidual 등등)에 따라서 해당 module의 parameter의 종류,search space도 달라짐

#### 모델 경량화 관점에서의 AutoML

모델을 경량화하는 것은 두가지 관점이 존재합니다.  

기존 모델 경량화 vs 새로운 경량 모델 Search

- 기존 모델 경량화 : Pruning, Tensor decomposition, ... -> 이러한 기법들은 후처리가 있어야 성능이 나옵니다.  
- **새로운 경량 모델 Search** : NAS(Neural Architecture Search), Auto
 
### Basic Concept

#### AutoML Pipeline

**일반적인 AutoML Pipeline**  

Configuration : Backbone, hyperparam 모두 포괄  
Evaluate Objective : 어떤 Task에 따라 다르다? -> 성능, 속도 or 성능 등등 Task마다 원하는 수치 값을 설정해준다.  
Blackbox objective : 평가한 Objective값을 가지고 평가 지표를 최대로 만드는 람다를 찾는 것

  ![tmp](/assets/images/AI-Images2/lv3_week3/img20.png)

AutoML Pipeline 예시 : Bayesian Optimization (BO)  
Blackbox objective : Surrogate Function -> Acquisition Function  
Surrogate Function : $f(\lambda)$ 를 예측하는 Regression 모델  
Acquisition Function : 다음 $\lambda$ 를 시도하는 함수  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img21.png)

#### Bayesian Optimization (with Gaussian Process Regression)



Surrogate Function과 Acquisition Function을 자세하게 살펴보면,  
3번의 objective 계산 후, point가 업데이트 되는 것을 볼 수 있습니다.  
point가 업데이트 됨에 따라 Surrogate model이 업데이트 됩니다. 그에 따라, 점선과 보라색 영역이 줄어들면서 좀 더 정밀해집니다.  
Acquisition function은 다음 $\lambda$ 를 추천해주는 함수가 업데이트 됩니다.  
위와 같은 과정을 반복합니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img22.png)

간단 설명 : Gaussian Process Regression

- 일반적인 Regression task : "Estimate the function f fits the data the most closely"  
  Set of train data: (X, Y), Set of the test data : (X*, Y*), $Y \approx f(X)+e$  

- 우리가 알고자 하는 특정 위치의 Y*값은 우리가 알고 있는 X, Y, X*들과 (positive건, negative건) 연관이 있지 않을까?  
  -> X, Y, X* 값으로부터 Y*를 추정, 연관에 대한 표현은 Kernel 함수 K로 표현

- f(x)를 "Possible output of the function f at input x"인 "Random variable"로 보고, 각 r.v.들이 Multivariate Gaussian distribution 관계에 있다고 가정  
= 함수들의 분포를 정의하고, 이 분포가 Multivariate Gaussian distribution을 따른다 가정
= 함수 f가 Gaussian process를 따른다.  

$\left[\begin{array}{l}\mathbf{f} \\ \mathbf{f}_{*}\end{array}\right] \sim \mathcal{N}\left(\mathbf{0},\left[\begin{array}{ll}K(X, X) & K\left(X, X_{*}\right) \\ K\left(X_{*}, X\right) & K\left(X_{*}, X_{*}\right)\end{array}\right]\right)$


Surrrogate function은 적절한 관계성을 가지는 Function을 찾아주는 것

Acquisition Function은 적절한 관계성 속에서 가장 적절한 위치를 찾아주는 것

