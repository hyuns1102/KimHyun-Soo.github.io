---
title: "[ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ ìº í”„] AI-Tech-re - week2(4) - Transformer"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

[RNN](https://hyuns1102.github.io/ai/boostcourse/AItech-9/)ì— ì´ì–´ì„œ Transformerì— ëŒ€í•œ ë‚´ìš©ì´ë‹¤.  

[ì›ë³¸ ë§í¬](https://nlpinkorean.github.io/illustrated-transformer/) ë§¤ìš° ë§ì´ ì°¸ê³   
[ì›ë¬¸ ë§í¬](https://jalammar.github.io/illustrated-transformer/) ì°¸ê³   
[ì›ë³¸ ë…¼ë¬¸ Attention is All you Need](https://arxiv.org/abs/1706.03762) ì°¸ê³   
[logit, softmax, Sigmoid ê´€ë ¨ ì„¤ëª… ì°¸ê³ ê¸€](https://chacha95.github.io/2019-04-04-logit/)
  
#### Transformer

ë¬¸ì¥ì˜ Sequenceê°€ ìˆì„ ë•Œ, ë‹¨ì–´ê°€ ëŠê¸°ê±°ë‚˜ ìƒëµë˜ê±°ë‚˜ í•œë‹¤ë©´ ? ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œ? ë¼ëŠ” ì˜ë¬¸ì—ì„œ ì‹œì‘ë˜ì—ˆë‹¤.  
ì¸ì½”ë”© ì´ì „ì— linear ëª¨ë¸ì„ í†µê³¼í•œ í›„ì— ë‚˜ì˜¨ vectorë¥¼ ì´ìš©í•´ì„œ ì¸ì½”ë”©ì„ ì‹œì‘í•œë‹¤.  

  ![s1](/assets/images/AI-Images/img71.png)

```python
ğŸ“¢ëª¨ë¸ì˜ í•µì‹¬ì„ ì •ë¦¬í•˜ìë©´,  
Mutil-head Self-Attentionì„ ì´ìš©í•´ì„œ Sequentail Computationì„ ì¤„ì´ê³ ,  
ë§ì€ ë¶€ë¶„ì„ ë³‘ë ¬ì² ë¦¬ê°€ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ì–´ì„œ ë” ë§ì€ ë‹¨ì–´ë“¤ ê°„ Dependecyë¥¼ ëª¨ë¸ë§ í•©ë‹ˆë‹¤.  
```

- Overview of Architecture

  black boxë¥¼ ì—´ê¸° ì „ì—, ì „ì²´ì ì¸ ArchitectureëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  

  ![s1](/assets/images/AI-Images/img72.png)

  ìœ„ì˜ TransFormerë¼ëŠ” boxë¥¼ ì—´ì–´ë³´ê²Œ ë˜ë©´, encoding, decodingë¶€ë¶„ë“¤ê³¼ ê·¸ ì‚¬ì´ connectionì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì—ì„œ ë³´ë“¯ì´ í•˜ë‚˜ì˜ ë¬¸ì¥ì´ Encoderë¥¼ í†µí•´ ë“¤ì–´ê°€ì„œ decoderë¥¼ í†µí•´ ë²ˆì—­ë˜ì–´ ë‚˜ì˜¤ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

  ![s1](/assets/images/AI-Images/img73.png)

- Sequence to Sequence Transformer  

  Sequence í•˜ë‚˜ë‹¹ nê°œì˜ ë‹¨ì–´ ëª¨ë‘ë¥¼ ì¸ì½”ë”©í•  ìˆ˜ ìˆë‹¤.  

  <details>
  <summary> a. Nê°œì˜ ë‹¨ì–´ê°€ ì–´ë–»ê²Œ ì¸ì½”ë”ì—ì„œ ì²˜ë¦¬? </summary>
  <div markdown="1">

  Encoder ë‚´ë¶€ë¥¼ ì¢€ ë” ìì„¸í•˜ê²Œ ë³´ë©´ **Self-Attention**ê³¼ **Feed Forward Neural Network**ë¼ëŠ” 2ê°œì˜ Sub layerë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.  

    ![s1](/assets/images/AI-Images/img49.png)

    â—Self-attention : 3ê°œì˜ ë‹¨ì–´ì— ëŒ€í•œ 3ê°œì˜ ë²¡í„° -> 3ê°œì˜ ë²¡í„°ë¥¼ ì¶œë ¥í•´ì¤€ë‹¤.  
    ì—¬ê¸°ì„œ self-attentionì€ ë‚˜ë¨¸ì§€ ë‹¨ì–´ë“¤ì— ëŒ€í•´ dependenciesê°€ ì¡´ì¬í•œë‹¤.  
    ex) self-attention at high-level  

    â—Feed forward Neural Network : self-attentionì—ì„œ ì¶œë ¥ëœ vectorë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.  

    ![s1](/assets/images/AI-Images/img75.png)

    â—Word Embedding  
    ê° ë‹¨ì–´ë“¤ì„ Inputì— ì´ìš©í•˜ê¸° ìœ„í•´ì„œ Embedding Vectorë¡œ ë§Œë“­ë‹ˆë‹¤.  
    [Embedding Algorithms ê´€ë ¨ ë§í¬](https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca)

    ![s1](/assets/images/AI-Images/img74.png)

  - Encoding ê³¼ì •  

    <details>
    <summary>Self-Attention</summary>
    <div markdown="1">

    "Thinking Machines"ë¼ëŠ” Sentenceê°€ Encoding ë˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

    ![s1](/assets/images/AI-Images/img76.png)

    1. Self-Attentionì—ì„œ í•´ì•¼í•  ì²« ë‹¨ê³„ëŠ” 3ê°œì˜ ë²¡í„°ë¥¼ ë§Œë“œëŠ” ì¼ì…ë‹ˆë‹¤. ê° 3ê°œì˜ í•™ìŠµ ê°€ëŠ¥í•œ í–‰ë ¬ë“¤ì„ ê³±í•´ì„œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.  

        ì—¬ê¸°ì„œ ì•Œì•„ë‘ì–´ì•¼í•  ì ì€, ê¸°ì¡´ ì…ë ¥ ë²¡í„°ë“¤ì˜ í¬ê¸°ê°€ 512(ê·¸ë¦¼ì—ì„œëŠ” 4)ì¸ ë°˜ë©´ ìƒˆë¡œìš´ ë²¡í„°ë“¤ì˜ í¬ê¸°ëŠ” 64 (ê·¸ë¦¼ì—ì„œëŠ” 3) ì´ ë©ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” í›„ì— Multi-head Attentionì˜ ê³„ì‚° ë³µì¡ë„ë¥¼ ë§ì¶”ê¸° ìœ„í•´ì„œ headì˜ ê°œìˆ˜ë§Œí¼ dimensionì„ ë‚˜ëˆ ì¤¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  
        ğŸ’¡64 = 512 / 8 (head)  

        ![s1](/assets/images/AI-Images/img78.png){: width="80%" height="80%"}

        <br>

    2. Embedding vector / Queries / Keys / Values ì˜ ë²¡í„°ë“¤ì„ í•˜ë‚˜ì”© ìƒì„±í•´ì£¼ê³  Queries, Keys vectorì‚¬ì´ì˜ ë‚´ì ì„ í†µí•´ Score vectorë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤. (ì–¼ë§ˆë‚˜ ê´€ê³„ ìˆëŠ”ì§€)  
        ğŸ’¡ë‚´ì ì„ í•  ë–„ëŠ” í˜„ì¬ ë‹¨ì–´ì™€ ì´ì „, ì´í›„ keyì™€ì˜ ë‚´ì ì„ í†µí•´ì„œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.  
        ğŸ’¡ì—¬ê¸°ì„œ ë§í•˜ëŠ” Queries, keys, valuesëŠ” ì¶”ìƒì ì¸ ê°œë…!  

        ![s2](/assets/images/AI-Images/img50.png)

        <br>

    3. ê·¸ ë‹¤ìŒ Scoreë¥¼ Normalization (Key Vectorì˜ dimensionì˜ ì œê³±ê·¼) í•œ í›„, Softmax í•¨ìˆ˜ë¥¼ í†µí•´ ê³„ì‚°í•œ ë‹¤ìŒì— ê°€ì§€ê³  ìˆëŠ” Value vectorì— ê³±í•´ì¤€ë‹¤. (weighted Sum of the value vectors)  
      ğŸ’¡Normalizationì˜ ì´ìœ ëŠ” ê° Wì˜ dimensionì´ ë†’ì•„ì§ì— ë”°ë¼ ê° ìš”ì†Œë³„ë¡œ í¬ê¸°ê°€ ì»¤ì§€ê¸°ì— ë¶ˆì•ˆì •í•œ Gradientë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

        ![s3](/assets/images/AI-Images/img51.png)

      ì´ êµ¬ì¡°ëŠ” ì…ë ¥ê³¼ ì¶œë ¥ì´ ê³ ì •ë˜ì–´ ìˆëŠ” êµ¬ì¡°ê°€ ì•„ë‹ˆë¼, ì…ë ¥ì— ì–´ë–¤ ë‹¤ë¥¸ Sequenceê°€ ë“¤ì–´ì˜¤ë©´ ì¶œë ¥ì´ ê³„ì† ë‹¬ë¼ì§€ê²Œ ëœë‹¤.  
      ì¦‰, í‘œí˜„ë ¥ì´ ë§ì•„ì§„ë‹¤. -> ë§ì€ computation(ê³„ì‚°) ì´ í•„ìš”  

      ğŸ’¡Key, Query, Value vector ê°ê° ì°¾ì•„ë‚´ëŠ” MLPê°€ ì¡´ì¬í•œë‹¤. 

      <br>

      *ìœ„ì˜ ê³¼ì •ì„ í–‰ë ¬ ë‹¨ìœ„ë¡œ, ë‹¤ì‹œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.*  

      ![s1](/assets/images/AI-Images/img77.png){: width="60%" height="60%"}

      ![s4](/assets/images/AI-Images/img52.png)

    </div>
    </details>

    <details>
    <summary>Multi Headed Attention (MHA)</summary>
    <div markdown="1">

    í•˜ë‚˜ì˜ Inputì— ìœ„ì™€ ê°™ì€ Self-attentionì„ ë°˜ë³µí•´ì„œ Nê°œì˜ Headë¥¼ ë§Œë“¤ê²Œ ë˜ëŠ” ë°, ì´ë¥¼ MHAë¼ê³  í•œë‹¤.  
    MHAë¥¼ í•˜ëŠ” ì´ìœ ëŠ”  
    ì²«ë²ˆì§¸ë¡œ, ëª¨ë¸ì´ ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œë„ ì§‘ì¤‘í•˜ëŠ” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.  
    ì˜ˆì œ) â€œThe animal didnâ€™t cross the street because it was too tiredâ€ì—ì„œ itì´ ê°€ë¦¬í‚¤ëŠ” ê²ƒì´ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ” ì§€ ì•Œì•„ë‚¼ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.  
    ë‘ë²ˆì§¸ë¡œ, Attentionì´ ì—¬ëŸ¬ ê°œì˜ representation layerë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë„ë¡ í•´ì¤ë‹ˆë‹¤.  

    ![s5](/assets/images/AI-Images/img79.png)

    self-Attention ì´í›„, ì„œë¡œ ë‹¤ë¥¸ 8ê°œì˜ zí–‰ë ¬ì´ ë‚˜ì˜¤ê²Œ ë˜ëŠ”ë°, ì´ í–‰ë ¬ì„ ë°”ë¡œ feed-forward layerë¡œ ì“¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´ í•œ ìœ„ì¹˜ì— ëŒ€í•´ ì˜¤ì§ í•œ ê°œì˜ í–‰ë ¬ë§Œ Inputìœ¼ë¡œ ë°›ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  

    ![s4](/assets/images/AI-Images/img53.png)

    ì´ëŸ¬í•œ MHAë¥¼ í†µí•´ ë‚˜ì˜¨ Z ë²¡í„°ë“¤ì€ concatenatingì„ í•˜ê³  W0ë¼ëŠ” í° ê°€ì¤‘ì¹˜ ë²¡í„°ì— ì˜í•´ output Z ìƒì„±í•˜ê²Œ ë©ë‹ˆë‹¤. (CNNì˜ ë§ˆì§€ë§‰ì— flatten, Concatí•˜ëŠ” ê³¼ì •ê³¼ ë¹„ìŠ·)

    ![s4](/assets/images/AI-Images/img80.png)

    Self-Attentionê³¼ MHAë¥¼ í†µê³¼í•œ í›„, itì´ë¼ëŠ” ë‹¨ì–´ë¥¼ encodeí•  ë•Œ, ê°ê°ì˜ Attentionë“¤ì´ ì–´ë–¤ ë‹¨ì–´ë¥¼ ê°€ë¦¬í‚¤ëŠ” ì§€ ë³´ë©´, ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  
    ì²«ë²ˆì§¸ ê·¸ë¦¼ì˜ ê²½ìš°, itì´ "The", "animal" ê³¼ "tire", "-d"ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„, itì˜ representationì— í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
    ë‘ë²ˆì¨° ê·¸ë¦¼ì˜ ê²½ìš°, itì´ ìœ„ì˜ ë‹¨ì–´ë§ê³ ë„ ë§ì€ ë‹¨ì–´ë¥¼ representaitonì— í¬í•¨ì‹œí‚¤ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

    ![s5](/assets/images/AI-Images/img81.png) ![s5](/assets/images/AI-Images/img86.png)

    ì§€ê¸ˆê¹Œì§€ì˜ ëª¨ë“  ê³¼ì •ì„ í•˜ë‚˜ì˜ ê·¸ë¦¼ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´, ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  
    ì—¬ê¸°ì„œ ì•Œì•„ì•¼í•  ì ì€ ì²«ë²ˆì§¸ Attentionì—ì„œ Embedding ê³¼ì •ì´ ìˆê³  ë‚˜ë¨¸ì§€ëŠ” Encoderë¥¼ í†µí•´ ë‚˜ì˜¨ z vectorë¥¼ ê·¸ëŒ€ë¡œ Inputìœ¼ë¡œ í•©ë‹ˆë‹¤.  
    z vectorì˜ sizeëŠ” Encoder ê³¼ì •ì„ ê±°ì¹œ í›„, Inputì˜ sizeì™€ ê°™ê²Œ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤.  

    ![s4](/assets/images/AI-Images/img84.png)

    ë§ì€ ì •ë³´ë¥¼ ë‹´ê³  ìˆì§€ë§Œ, ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤. -> Positional Encoding

    </div>
    </details>

    <details>
    <summary>Positional Encoding</summary>
    <div markdown="1">

    Positional Encodingì€ ëª¨ë¸ì—ê²Œ ë‹¨ì–´ì— ëŒ€í•œ ìˆœì„œì˜ ì •ë³´ë¥¼ ì£¼ê¸° ìœ„í•´ì„œ ìœ„ì¹˜ë³„ë¡œ íŠ¹ì • íŒ¨í„´ì„ ë”°ë¥´ëŠ” ë²¡í„°ì…ë‹ˆë‹¤.  

    ![s5](/assets/images/AI-Images/img82.png){: width="80%" height="80%"}

    ì•„ë˜ ê·¸ë¦¼ì€ Embedding í¬ê¸°ê°€ 4ì¼ ë•Œ (ì‹¤ì œë¡œëŠ” 512) ì˜ˆì‹œì…ë‹ˆë‹¤.  
    SequenceëŠ” ì–´ë–»ê²Œ ë“¤ì–´ì˜¤ë“  ê°’ì´ encodingì— ì˜í•´ ë‹¬ë¼ì§ˆ ìˆ˜ê°€ ì—†ë‹¤. (orderì— independent)  
    ì–´ë–¤ ë‹¨ì–´ê°€ ì–´ëŠ ìœ„ì¹˜ì— ìˆëŠ” ì§€ ì¤‘ìš”í•˜ê¸°ì— ë„£ì–´ì¤€ë‹¤. (ë²¡í„°ê°’ì— offsetì„ ì¤Œ)  

    ![s6](/assets/images/AI-Images/img54.png)

    ì‹¤ì œ Encoding Vectorì˜ ì‹œê°í™”  

    ![s5](/assets/images/AI-Images/img83.png){: width="75%" height="75%"}

    </div>
    </details>

    <details>
    <summary>The Residuals</summary>
    <div markdown="1">

    Encoderë¥¼ ë” ëœ¯ì–´ë³´ë©´, ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
    Self-Attention ì´í›„, Feed Forwardë¥¼ ë°”ë¡œ ì§„í–‰í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ Layer Normalization ê³¼ì •ì„ í•œë²ˆ ê±°ì¹˜ê²Œ ë©ë‹ˆë‹¤.  
    [Layer Normalizationì— ê´€í•œ ë…¼ë¬¸ ë§í¬](https://arxiv.org/abs/1607.06450)  
    Sub layerì—ë„ ì ìš©í•œë‹¤ë©´ ë‘ë²ˆì§¸ ê·¸ë¦¼ê³¼ ê°™ì´ êµ¬ì¡°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

    ![s7](/assets/images/AI-Images/img55.png)
    
    </div>
    </details>

  </div>
  </details>

  <details>
  <summary> b. ì¸ì½”ë”ì™€ ë””ì½”ë” ì‚¬ì´ì— ì–´ë–¤ ì •ë³´ ì£¼ê³  ë°›ìŒ? </summary>
  <div markdown="1">


  - ì¸ì½”ë”ì—ì„œ ë””ì½”ë”ë¡œ ì–´ë–¤ ì •ë³´ë¥¼ ì£¼ê³  ë°›ëŠ”ê°€?  

    ![s8](/assets/images/AI-Images/img56.png)

    ê°€ì¥ ìœ—ë‹¨ì˜ Encoderì—ì„œ ì¶œë ¥ë˜ì—ˆë˜ vectorëŠ” attention ë²¡í„°ë“¤ì¸ Kì™€ Vë¡œ ë³€í˜•ë©ë‹ˆë‹¤.  
    ì´ ë²¡í„°ë“¤ì€ ì´ì œ ê° decoderì˜ "encoder-decoder attention0 layer"ì—ì„œ decoder ê°€ ì…ë ¥ vectorì—ì„œ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.  
    Key Vector ì™€ Value vector ê°’ì„ Decoderì— ì „ë‹¬í•´ì„œ previous outputê³¼ í•¨ê»˜ outputì´ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤.  

    Q : ë””ì½”ë”ì˜ ì´ì „ ë ˆì´ì–´ hidden state  
    K : ì¸ì½”ë”ì˜ output state  
    V : ì¸ì½”ë”ì˜ output state  

    ![s9](/assets/images/AI-Images/img57.png)

    ![How to use output of Encoder](https://nlpinkorean.github.io/images/transformer/transformer_decoding_1.gif)

  - Self-attention layer & Encoder-Decoder Attention  

    DecoderëŠ” EOS (End Of Sentence)ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ìˆœì°¨ì ìœ¼ë¡œ Decodingì„ ë°˜ë³µí•©ë‹ˆë‹¤.  

    ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´, Decoder ë˜í•œ Output Sequenceë¥¼ ì´ìš©í•´ì„œ ê°€ì¥ ë¨¼ì € Self-Attentionì„ ì§„í–‰í•©ë‹ˆë‹¤.  
    í•˜ì§€ë§Œ Decoderì˜ ê°€ì¥ ì•„ë«ë‹¨ì¸ Self-Attentionì€ Encoderì˜ self-attentionê³¼ ë‹¤ë¥´ê²Œ ì§„í–‰í•©ë‹ˆë‹¤.  
    EncoderëŠ” í•œë²ˆì— sentenceê°€ ë“¤ì–´ê°€ì„œ ë³‘ë ¬ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì£¼ë³€ ë‹¨ì–´ì™€ì˜ depenciesë¥¼ ì´ìš©í•˜ë©´ì„œ featureì˜ ì •ë³´ë¥¼ ìŒ“ì•˜ìŠµë‹ˆë‹¤.  

    í•˜ì§€ë§Œ Decoderì˜ ê²½ìš°, ì´ì „ output vectorë¥¼ ì´ìš©í•´ì„œ *ìˆœì°¨ì *ìœ¼ë¡œ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì— ë³‘ë ¬ ìˆ˜í–‰ì´ ë¶ˆê°€ëŠ¥í•˜ê²Œ ë©ë‹ˆë‹¤.  
    ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ, ë‹¤ìŒ ì¶œë ¥ì´ ë‚˜ì˜¤ì§€ ì•Šì€ ìƒí™©ì— ê·¸ ìë¦¬ì— -infì™€ ê°™ì´ ë§ˆìŠ¤í‚¹í•´ì„œ attentionì„ ì£¼ë©´ ë³‘ë ¬ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ê²Œ ë©ë‹ˆë‹¤.  

    ![s10](/assets/images/AI-Images/img58.png)

    "Encoder-Decoder Attention" layer ì€ multi-head self-attentionê³¼ ë¹„ìŠ·í•˜ê²Œ ì‘ìš©í•˜ëŠ” ë°, ì°¨ì´ì ì€ Query í–‰ë ¬ë“¤ì„ ê·¸ ë°‘ì˜ layerì—ì„œ ê°€ì ¸ì˜¤ê³  Key ì™€ Value í–‰ë ¬ë“¤ì„ encoderì˜ ì¶œë ¥ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.  

    ![s11](/assets/images/AI-Images/img59.png)

    ë‹¤ìŒì€ Decoder ê³¼ì •ì— ëŒ€í•œ ë™ì‘ì…ë‹ˆë‹¤.  

    ![Decoding Course](https://nlpinkorean.github.io/images/transformer/transformer_decoding_2.gif){: width="80%" height="80%"}

  </div>
  </details>

  <details>
  <summary> c. ë””ì½”ë”ê°€ ì–´ë–»ê²Œ generalize í•  ìˆ˜ ìˆëŠ”ì§€? </summary>
  <div markdown="1">

  ì—¬ëŸ¬ ê°œì˜ Decode ê³¼ì •ì„ ê±°ì¹œ í›„, Encoderì™€ ë¹„ìŠ·í•˜ê²Œ í•˜ë‚˜ì˜ vectorë¡œ ì¶œë ¥ë©ë‹ˆë‹¤. ì´ ë§ˆì§€ë§‰ vectorë¥¼ ë‹¨ì–´ë¡œ ë°”ê¾¸ëŠ” ê²ƒì´ **Linear Layerì™€ Softmax Layer**ê°€ í•˜ëŠ” ì¼ ì…ë‹ˆë‹¤.  

  Linear LayerëŠ” Outputìœ¼ë¡œ ë‚˜ì˜¨ vectorì˜ ê° ì…€ì„ logits vectorë¡œ íˆ¬ì˜ì‹œí‚¤ëŠ” ì—­í• ì…ë‹ˆë‹¤.  
  logits vectorë€? sigmoid í•¨ìˆ˜ì˜ ì—­í•¨ìˆ˜ë¡œ, Sigmoidê°€ [0, 1] ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í™•ë¥ ì„ ë‚˜íƒ€ë‚¸ë‹¤ë©´,
  ì´ëŸ¬í•œ logit vectorëŠ” Softmaxë¥¼ ì´ìš©í•´ì„œ ì „ì²´ í•©ì´ 1ì´ ë˜ëŠ” í™•ë¥  ê°’ìœ¼ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ vectorì…€ì˜ indexë¥¼ ì„ íƒí•´ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

  ![s11](/assets/images/AI-Images/img85.png)

  </div>
  </details>