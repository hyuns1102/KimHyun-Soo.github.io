---
title: "[ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ ìº í”„] AI-Tech - Lv2 week2(5)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## í•™ìŠµê¸°ë¡ - 35

ì˜¤ëŠ˜ í•  ì¼

- Multi-Modal learning - Image Captioning
- 3D Understanding

## 1. ê°•ì˜ ë³µìŠµ ë‚´ìš©

### Multi-Modal learning

- Image Captioning  

  [Pytorch Tutorial - Image Captioning](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning)

  Image Captionì€ ì•„ë˜ì˜ ì´ë¯¸ì§€ì²˜ëŸ¼ attention ëœ ì´ë¯¸ì§€ë¥¼ í†µí•´ sentenceë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒ  

  ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img1.png){: width="" height=""}  

  Encoder ë¶€ë¶„  
  ì´ë¯¸ì§€ë¥¼ pre-trainedëœ ëª¨ë¸ì— ë„£ì–´ classification ì´ì „ê¹Œì§€ (linear, pool layer ì œì™¸) ì‚¬ìš©  

  ```python
  class Encoder(nn.Module):
    """
    Encoder.
    """

    def __init__(self, encoded_image_size=14):
        super(Encoder, self).__init__()
        self.enc_image_size = encoded_image_size

        resnet = torchvision.models.resnet101(pretrained=True)  # pretrained ImageNet ResNet-101

        # Remove linear and pool layers (since we're not doing classification)
        modules = list(resnet.children())[:-2]
        self.resnet = nn.Sequential(*modules)
  ```

  Decoder ë¶€ë¶„  

  Encoded Imageë¥¼ RNNì— feeding  
  Attention Imageì™€ wordë¥¼ decoderì— ë„£ì–´ ë‹¤ìŒ word ì¶œë ¥  

  ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img2.png){: width="" height=""}  

  Beam Search  
  ê°€ì¥ ì²˜ìŒì— ë¶€ë¶„ë¶€í„° wordê°€ í‹€ë ¸ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ì„œ Beam Searchë¥¼ ì´ìš©  
  decode step ë§ˆë‹¤ top3 sequenceë¥¼ ë½‘ëŠ”ë‹¤. "end" í† í°ì´ ë‚˜ì˜¬ ê²½ìš°, ê°€ì¥ ë†’ì€ ìŠ¤ì½”ì–´ ì„ íƒ  

  ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img3.png){: width="" height=""}  

### 3D Understanding  

Applications - Medical applications, 3D print, AR/VR  

If you are interested in more details about 3D, check this Bible.
[Multiple View Geometry in Computer Vision](https://www.cambridge.org/core/books/multiple-view-geometry-in-computer-vision/0B6F289C78B2B23F596CAA76D3D43F7A)

3D data representation  

![Untitled](/assets/images/AI-Images2/lv2_week2_1/img4.png){: width="" height=""}

- 3D dataset  
  - ShapeNet  
    Large scale synthetic objects (51,300 3D models with 55 categories)
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img5.png){: width="" height=""}

  - PartNet  
    Fine-grained dataset, useful for segmentation (573,585 part instances in 26,671 3D models)
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img6.png){: width="" height=""}

  - SceneNet  
    5 million RGB-Depth synthetic indoor images
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img7.png){: width="" height=""}

  - ScanNet  
    RGB-Depth dataset with 2.5 million views obtained from more than 1500 scans
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img8.png){: width="" height=""}

  - Outdoor 3D Scene datasets  
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img9.png){: width="" height=""}

- 3D recognition  
  - Various tasks for 3D data  
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img10.png){: width="" height=""}

  - 3D object recognition  
    2D Imageì—ì„œ class ë¶„ë¥˜ì™€ ê°™ì´ 3D Imageì—ì„œë„ ê°™ì€ recognitionì„ ì§„í–‰  
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img11.png){: width="" height=""}

  - 3D object detection  
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img12.png){: width="" height=""}

  - 3D semantic Segmentation  
    ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img13.png){: width="" height=""}

  - Conditional 3D generation
    - Mesh R-CNN (Mask R-CNNì˜ headë¥¼ Mesh í˜•íƒœë¡œ Modification)  
      ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img14.png){: width="" height=""}
    
    - "3D branch" is added to Mask R-CNN  
      ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img15.png){: width="" height=""}

    - More Complex 3D reconstruction models  
      - Decomposing 3D object reconstruction into multiple sub-problems  
      - Sub-problems: physically meaningful disentanglement (Surface normal, depth, silhouette, â€¦)

        ![Untitled](/assets/images/AI-Images2/lv2_week2_1/img16.png){: width="" height=""}

 





## 2. ê³ ë¯¼ ë‚´ìš©, ê²°ê³¼ (ê³¼ì œ ìˆ˜í–‰ ê³¼ì •, ê²°ê³¼ë¬¼ ì •ë¦¬)

### ê³¼ì œ

## 3. í”¼ì–´ì„¸ì…˜ ì •ë¦¬

[ 2021ë…„ 9ì›”16ì¼  ëª©ìš”ì¼ íšŒì˜ë¡ ]

âœ… ì˜¤ëŠ˜ì˜ í”¼ì–´ì„¸ì…˜ (ëª¨ë”ë ˆì´í„°: ë°±ì¢…ì›)

1. ê°•ì˜ ìš”ì•½
    - ë°œí‘œì: ë°±ì¢…ì›
    - ë‚´ìš© : Multi-modal Learning

ğŸ“¢Â í† ì˜ ë‚´ìš©

1. í•„ìˆ˜ê³¼ì œ 4ë²ˆ ê´€ë ¨ ì—ëŸ¬
2. GAN Implements : [https://github.com/eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN) (ê³µìœ : ì¡°ì¤€í¬ ìº í¼ë‹˜)

ğŸ“¢ ë‚´ì¼ ê°ì í•´ì˜¬ ê²ƒ

1. ëª¨ë”ë ˆì´í„°: ì´ì–‘ì¬  ìº í¼ë‹˜

ğŸ“¢ ë©˜í† ë§ ì§ˆë¬¸ ì‚¬í•­

## 4. í•™ìŠµ íšŒê³ 

- ìƒê°ë³´ë‹¤ ì–‘ì´ ë§ê³  ì–´ë ¤ì› ë˜ ê²Œ ë§ì•˜ë˜ ê³¼ì •ì´ë‹¤. ê·¸ëŸ°ë° ì‹œê°í™”ê°€ ì•„ë‹Œ sound ë“±ì„ í•¨ê»˜ ì´ìš©í•  ìˆ˜ ìˆëŠ” multi-modal learningì— ëŒ€í•´ í¥ë¯¸ê°€ ë§ì´ ìƒê²¼ë˜ ê°•ì˜ì˜€ë‹¤.  