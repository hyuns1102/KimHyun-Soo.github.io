---
title: "[네이버 부스트 캠프] AI-Tech - Lv2 week8(2)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 56

## 1. 강의 복습 내용

### 1.1 Ensemble

1. 5-fold Ensemble  
  5-FOld Cross validation을 통해 만들어진 5개의 모델을 Ensemble하는 방법  

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img1.png)

2. Epoch Ensemble  
  학습을 완료한 후, 마지막부터 N개의 weight을 이용해 예측한 후 결과를 Ensemble하는 방법  
  체크 포인트를 모두 모와서 Ensemble  

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img2.png)

3. SWA (Stochastic Weight Averaging)  
  각 step마다 weight를 업데이트 시키는 SGD와 달리 일정 주기마다 weight를 평균 내는 방법  
  (질문) 무슨 얘기인지? constant lr vs cyclic lr, weight에 대해서 평균?

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img3.png)

  해당 알고리즘에 대한 코드는 다음과 같이 진행됩니다.  

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img4.png)

4. Seed Ensemble  
  Random한 요소를 결정짓는 Seed만 바꿔가며 여러 모델을 학습시킨 후 Ensemble하는 방법  
  Private에 대해서 일반성 강화 (Lucky seed에 대한 앙상블)

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img5.png)

5. Resize Ensemble  
  Input size의 이미지를 다르게 학습해서 Ensemble하는 방법  

6. TTA (Test time Augmentation)  
  Inference 시에, Image의 Aug 적용  
  독립적인 모델이 아닌 동일 모델에 대해서 Input을 다르게 적용하고 그 결과를 평균냅니다.  
  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img6.png)

  Segmentation의 경우, Input의 Augmentation된 경우가 그대로 나오기 때문에 다시 원본 형태로 바꿔주는 과정이 필요합니다.  

  (질문) 256 x 256 으로 Inference 한 다음에 다시 키워주는 과정을 만든다? 현재 Segmentation 같은 경우, 그대로?

  학습 때와 다른 size의 Input 이미지를 이용해 Test(Inference)하는 방법 (일종의 TTA)  

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img7.png)

  보통 직접 구현을 하는 경우도 있지만, TTA Library - ttach 를 이용해서 하기도 합니다.  
  
  - SegmentationTTAWrapper object는 model과 Compose의 결과물을 입력으로 받아 한 이미지에 대해 12 가지의 TTA를 적용하고 결과물을 평균 내어 return
  - Compose 오브젝트는 입력으로 주어진 TTA들을 조합해서 여러가지 TTA case 설정
  - 이전에 말했던 Inference 이 후, 다시 Image를 test size에 맞게 돌리는 경우까지 포함되어 나오게 됩니다. 
  - Merge modes에서 여러 기법들이 있는 데 이를 이용해서 실험 가능  
  
  [(출처) https://github.com/qubvel/ttach](https://github.com/qubvel/ttach)

  ```python
  import ttach as tta
  transforms = tta.Compose(
      [
          tta.HorizontalFlip(),
          tta.Rotate90(angles=[0, 180]),
          tta.Scale(scales=[1,2,4])
      ]
  )

  tta_model = tta.SegmentationTTAWrapper(model, transforms)
  masks = tta_model(imgaes)
  ```

#### 1.2 Pseudo Labeling

  Pseudo Labeling은 Test 데이터를 학습한 모델에 Inference하고 난 다음에,  
  그 결과를 다시 학습에 이용하는 방법입니다.  

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img8.png)

#### 1.3 외부 데이터 활용

  Kaggle, Github  
  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img9.png)

#### 1.4 그외

  Classification 결과를 활용하는 방법
  - Encoder Head 마지막 단에 Classification Head를 달아서 같이 활용 (Unet3+)

    ![tmp](/assets/images/AI-Images2/lv2_week12_2/img10.png)

  한정된 시간을 효율적으로 사용  

  - 코드를 돌리는 시간에 다른 작업 진행
  - 작은 샘플로 실험 코드가 문제 없는지 미리 확인
  - 자는, 쉬는 시간 등 GPU가 쉬지 않도록 미리 실험용 코드 작성  

### 2. 대회에서 사용하는 기법들 소개

#### 2.1 최근 딥러닝 이미지 대회 Trend

  대회는 다음과 같이 있습니다.  
  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img11.png)

  대회들의 문제점을 뽑자면, 다음과 같습니다.  

  1. 학습 이미지가 많고 큰 경우에는 네트워크를 한번 학습하는데 시간이 오래 걸려서 충분한 실험을 하지 못함  
    - "[이미지] 한국인 헤어스타일 세그먼테이션 모델" 의 경우, v100 2대로 9대1로 HoldOut 한 경우 학습을 완료하는데 24~30 시간 정도 걸림
    - 2주도 안되는 시간 동안 실험을 총 10개 가까이 밖에 못하는 문제가 발생
    - **Sol** : FP16, 실험 간소화, 가벼운 모델 사용
      - Solution1 : Mixed-Precision Training of DNN (FP16)
        weight의 소수점 자리를 32에서 16으로 대체하여 배치를 키우는 방법

        보통 AMP 없이는 모든 계산이 default precision인 torch.float32로 계산하게 됩니다.

        ```python
        net = make_model(in_size, out_size, num_layers)
        opt = torch.optim.SGD(net.parameters(), lr=0.01)

        start_timer()
        for epoch in range(epochs):
            for input, target in zip(data, targets):
                output = net(input)
                loss = loss_fn(output, target)
                loss.backward()
                opt.step()
                opt.zero_grad()
        ```

        위에서 torch.cuda.amp.autocast()를 적용해서 소수점 자리를 대체 해줍니다.  

        ```python
        net = make_model(in_size, out_size, num_layers)
        opt = torch.optim.SGD(net.parameters(), lr=0.01)
        scaler = torch.cuda.amp.GradScaler(enabled=use_amp) 
        # GradScaler는 AMP활용 시 발생할 수 있는 underflow 문제 방지
        # backward(), step() 호출 시 필요

        for epoch in range(epochs):
            for input, target in zip(data, targets):
                with torch.cuda.amp.autocast(enabled=use_amp):
                    output = net(input)
                    loss = loss_fn(output, target)
                scaler.scale(loss).backward()
                scaler.step(opt)
                scaler.update() # 단계 하나 추가
                opt.zero_grad()
        ```

      - Solution 1-2 : 가벼운 상황으로 실험
        - 일부 데이터 사용
        - 단, **LB와 Validation Score 간에 어느 정도 상관관계**가 있어야 함.
        - K-Fold 보다는 단일 Fold로 검증

          예시)
          일부 데이터를 이용한 실험  

            ![tmp](/assets/images/AI-Images2/lv2_week12_2/img12.png)  
            
          이미지 데이터의 size를 줄이는 방법 or 학습 데이터의 일부만을 사용해서 실험  

            ![tmp](/assets/images/AI-Images2/lv2_week12_2/img13.png)  

          2048 x 2048 이미지를 다음과 같은 convolution과 maxpool을 적용시켜서 1024x1024, 8채널의 이미지로 학습 -> 시간 절약  
          
            ![tmp](/assets/images/AI-Images2/lv2_week12_2/img14.png)  

      - Solution 1-3 : 가벼운 모델로 실험
        - Parameter가 적은 모델로 실험하고 최종은 성능이 잘 나오는 모델로 확인하는 방법이 있습니다.

  2. 주어진 data인 Image의 크기가 매우 클 때, model이 학습하는 시간이 매우 오래 걸림.  
        ![tmp](/assets/images/AI-Images2/lv2_week12_2/img15.png)

      - Solution 2-1 : Resize
        주어진 데이터를 모두 resize 시켜서 학습 -> test set에 대해 예측된 Mask를 원본 size로 복원
        -> 하지만 Image가 지나치게 크다면 Resize 기법에 의해 Resolution이 감소

          ![tmp](/assets/images/AI-Images2/lv2_week12_2/img16.png)

      - Solution 2-2 : Sliding Window (**Overlapping** / Non-overlapping)  
        Image size가 크기 때문에 window 단위로 잘라서 Input으로 넣는 기법  
        Overlapping의 경우,  
        Window size > stride size로 진행되며, 이미지가 조금 겹치게 patch를 만들어 붙인다.  
        
          ![tmp](/assets/images/AI-Images2/lv2_week12_2/img17.png)

        Solution 2-2 : Sliding Window (Overlapping / **Non-overlapping**)  
        Non-Overlapping의 경우,  
        Window size = stride size 로 진행되며, 이미지가 원본 그대로 올 수 있다.
        
          ![tmp](/assets/images/AI-Images2/lv2_week12_2/img18.png)


        - 장점

            Window size가 클 경우, Input Image의 크기가 커지면서 동시에 정보를 많이 얻을 수 있습니다. (Object가 다 잡힐 수도 있다.)

            Stirde size가 작을 경우, Input Image 수가 증가하면서, 겹치는 영역이 많아지고, 다양한 정보를 얻을 수 있습니다. (Objec를 구분하기 위한 정보를 얻을 수 있다.)
            또한, 중복되는 부분에 대한 Ensemble을 통해 약간의 성능 향상을 얻을 수 있습니다.  

        - 단점

            다양한 정보를 얻을 수 있지만 학습 *데이터의 양이 많아서 늘어나게 될 수 있으며*, 중복되는 정보가 많아 학습 데이터가 늘어나는 양에 비해서 *성능의 차이는 적고 학습 속도가 오래 걸립니다.*

      - Solution 2-3 그 외 Tips 1

        - train에 사용된 sliding window의 크기 (512) 와 inference에 사용되는 sliding window의 크기가 동일해야 한다고 생각하는 경우가 많지만, Input Image의 크기가 꼭 같을 필요가 없습니다. 오히려 **Inference image의 sliding window의 크기가 커지면** 더 많은 주변 정보를 통해서 prediction 할 수 있으므로 **성능의 정확도가 올라가는 경우**가 있을 수 있습니다.  

      - Solution 2-3 그 외 Tips 2

        Sliding window를 적용하면 아래와 같이 유의미하지 않은 영역들이 잡힌 경우가 많음  
        - "background" 일 경우, 조금만 sampling 해서 (학습을 덜 참여하도록) 학습속도를 상승시킴.  

      - Solution 2-3 그 외 Tips 3

        Tips 2와 같은 문제에서, Center 부분만 prediction mark로 사용하는 방법  

          ![tmp](/assets/images/AI-Images2/lv2_week12_2/img19.png)
    
      - Solution 2-3 그 외 Tips 4  
        전체 이미지에서의 유의미하지 않은 영역들이 잡히는 경우,  
        
        segmentation / object detection을 통해서 object를 먼저 찾은 후 Crop  

          ![tmp](/assets/images/AI-Images2/lv2_week12_2/img20.png)

  3. Task가 Binary Classification인 경우  
    - 추가로 구분해야 할 class가 오직 Binary Case와 같은 경우 threshold인 prop을 0.5로 끊는게 정답이 아닐 수 있습니다. 
    - Threshold를 잘 search 하면서 실험 진행  

#### 2.2 model의 개선하기 위한 tips

  Output Image 확인

  - 큰/작은 object를 잘 예측할 수 있는지? 
  - 특정 class에 대해 잘 맞추는지?
    - class가 많은 경우 각각의 class를 찾아서 확인이 어려움. valid set에서의 IoU 값 확인

#### 2.3 Label Noise

  Label Noise가 생기는 경우가 있습니다.  

  ![tmp](/assets/images/AI-Images2/lv2_week12_2/img21.png)

  그 이유는, 일반적으로 segmentation에서의 annotation task는 픽셀 단위  
  annotation guide에 대해 사람마다 기준이 다르고 실수가 있을 수 있다.  

  Label Noise 연구 진행

  Solution1 Label Smoothing  
  - 가장 대표적으로 사용되는 방법은 Soft한 Loss를 사용하는 방법이 있습니다.  

    ![tmp](/assets/images/AI-Images2/lv2_week12_2/img22.png)
C:\Users\hyuns\gitblog\assets
  Solution2 Pseudo-labeling을 활용한 Label Preprocessing
  - 실제 Data를 학습을 통해 예측을 했을 때, 이미지의 mIoU가 상당히 낮은 경우, 실제로 예측을 못하는 경우도 있지만, Label에 Noise가 생기는 경우가 있을 수도 있습니다. (mIoU < 0.3)

  - 이러한 경우, 너무 noise가 심한 사진의 경우 Dataset에서 제외시켜주거나, 낮은 데이터를 pseudo labeling 시켜서 다시 학습에 참여하도록 합니다.  
    ![tmp](/assets/images/AI-Images2/lv2_week12_2/img22.png)

#### 2.4 최근 딥러닝 이미지 대회의 평가 Trend

기존 평가 방식인 Accuracy, mIoU 이외에 다양한 평가 방식을 추가

- 학습 시간의 제한
  - 모델 여러 개에 대한 앙상블은 힘들다. 
  - Epoch Ensemble (한가지 모델)
- 추론 시간의 제한
- 속도 평가를 하는 경우

### 3. Monitoring Tool

- Weights & Bias
  - Visualization in W&B
    [(출처) https://wandb.ai/stacey/deep-drive/reports/Image-Masks-for-Semantic-Segmentation--Vmlldzo4MTUwMw](https://wandb.ai/stacey/deep-drive/reports/Image-Masks-for-Semantic-Segmentation--Vmlldzo4MTUwMw)

## 2. 고민 내용, 결과 (과제 수행 과정, 결과물 정리)

### 프로젝트 수행

https://www.notion.so/EDA-segmentation-7fd6037dfc164f6a988f5e90036722dc

## 3. 피어세션 정리

### 피어세션

## 4. 학습 회고
