---
title: "[네이버 부스트 캠프] AI-Tech - Lv3 모델 서빙(1)"
categories: AI boostcourse
tags: python
published: trues
use_math: true
---

# 학습 기록

## BentoML

### Introduction

FastAPI로 머신 러닝 서버를 개발할 때, 많은 모델을 만들려면 반복되는 작업이 존재합니다. (Config, FastAPI 설정 등) 이러한 작업에 대한 빠르고 간단한 작업이 필요하게 됩니다.  
이에 따라 더 쉬운 개발을 위해 본질적인 "Serving"에 특화된 라이브러리들이 등장하게 됩니다.

### 문제

문제 1: Model Serving Infra의 어려움  
- Serving을 위한 다양한 라이브러리, 사이즈가 큰 파일을 패키징
- Cloud Service에 지속적인 배포를 위한 많은 작업 필요
- BentoML : CLI로 위 문제의 복잡도를 낮춤

문제 2: Online Serving의 Monitoring 및 Error Handling  
- Online Serving으로 API 형태로 생성
- Error, Logging 추가 구현
- BentoML : Python Logging Module사용, Access Log, Prediction Log를 기본으로 제공  
  Config 수정을 통한 Logging Customizing, Prometheus 같은 Metric 수집 서버에 전송 가능

문제 3: Online Serving 퍼포먼스 튜닝의 어려움  
- BentoML : Adaptive Micro Batch 방식 채택, 많은 요청에도 높은 처리량

현재 많은 이용량을 보여줍니다.

### BentoML 특징

- 쉬운 사용성
- Online / Offlien Serving 지원
- Major 프레임워크 지원 (TF, Pytorch, Keras, ..)

### BentoML

이후부터 실습으로 진행,, 직접 해보기!
