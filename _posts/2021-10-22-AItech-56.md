---
title: "[네이버 부스트 캠프] AI-Tech - Lv2 week7(4)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 54

## 1. 강의 복습 내용

### U-Net Intro
  
U-Net은 본래 의료 계열 문제 상황을 해결하기 위해 고안된 Network Architecture 입니다.  

의료 계열에서의 주요 문제들을 살펴보면,  

- 데이터 부족 문제로 인해 데이터 학습에 문제가 생긴다.  
- Cell Segmentation 작업의 경우, 같은 클래스가 인접해 있는 셀 사이의 경계 구분 필요

### U-Net Architecture

U-Net 논문에서는, Contracting Path와 Expanding Path가 대칭인 U자 형을 이룸  

Contracting Path : 입력 이미지의 전반적인 특징 추출 (Context 포착) 하는 것과 down-sampling 수행  
Expanding Path : Localization을 가능하게 하는 것과 Up-Sampling 수행  

각 블록은 3x3 Conv-BN-ReLU가 2번씩 반복되는 구조를 가지고 있습니다.  
각 Convolution에 zero_padding을 적용하지 않기 때문에, Image size가 조금씩 줄어드는 것을 볼 수 있습니다.  

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img1.png)

위의 과정을 진행 후, 각각의 블록이 Contracting Path에서는 아래로 내려갈 때, 채널의 수가 2배씩 증가하는 것을 볼 수 있고 Expanding Path에서는 채널의 수가 2배씩 감소하는 것을 볼 수 있습니다.  

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img2.png)

그리고 같은 계층의 Encoder의 출력물과 Up-Conv의 결과를 Concat하는 과정을 통해 'skip-connection'이 적용되었다는 것을 볼 수 있습니다.  

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img3.png)

위의 구조들을 조금 더 자세하게 살펴봅니다.  

<details>
<summary> Contracting Path </summary>
<div markdown="1">

Contracting Path : 이미지 특징 추출

- 3x3 Conv Network + BN + ReLU) x 2
  - zero-padding을 적용하지 않기 때문에 Patch-size가 감소합니다. (572 -> 570 -> 568)
- 2x2 Max pooling (stride = 2)  
  - Feature Map의 크기가 절반으로 감소합니다. (568 -> 284)
- 가장 아래 단계에 왔을 때, Decoder로 넘어가기 전에 채널 수 2배 증가 (512 -> 1024), 증가하면서 첫번째 단계를 반복하기 때문에 size가 감소하게 됩니다.  

</div>
</details>

<details>
<summary> Expanding Path </summary>
<div markdown="1">

Expanding Path : Localization을 가능하게 함.  

- 2x2 Up-Conv 사용 (Transposed Convolution)  
  - Feature Map 크기가 2배 증가
  - 채널의 수를 절반으로 감소 (1/2배)

- Contracting에서 얻은 Feature Map과 Concat 진행 (skip-connection)
  - Contracting에서 얻은 Feature Map은 crop image을 통해서 Image의 size를 맞춰줄 수 있도록 합니다.ㅍㅍ
- (3x3convNet + BN + ReLU) X 2
  - No zero-padding으로 Patch-size가 감소하게 됩니다.  
    (질문) zero-padding을 준다는 얘기인가?

- 마지막 과정은 1x1 conv를 진행해서 output channel은 class 수로 만듭니다.  

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img4.png)

</div>
</details>

U-Net의 Contribution  

- Encoder가 확장함에 따라 채널의 수를 1024까지 증가시켜 좀 더 고차원에서 정보를 매핑  
- 각기 다른 계층의 Encoder의 출력을 Decoder와 결합시켜서 이전 레이어의 정보를 효율적으로 활용  

### U-Net에 적용된 Techniques

Data Augmentation  

- Random Elastic deformations 적용 - 물체에 왜곡을 조금 주는 방법 (세포의 모양을 다양하게 만들어준다.)
  - model이 invariance와 robustness를 학습할 수 있도록 하는 방법

    ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img5.png)

Pixel-wise loss weight를 계산하기 위한 weight map을 생성합니다.  

- 같은 클래스를 가지는 인접한 셀을 분리하기 위해 해당 경계부분에 가중치를 제공  
- 인접한 거리가 멀수록 경계 부분에 높은 가중치를 제공하고, 반대로 가까울수록 낮은 가중치를 제공합니다. 이를 loss 값에 반영해서 작은 경계 부분의 학습을 더 잘할 수 있게 만들어줍니다. (세포 사이)

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img6.png)


### U-net Code 분석

<details>
<summary> Code </summary>
<div markdown="1">

다음과 같이 각 블록별 Conv는 Convolution-BatchNorm-ReLU를 반복해서 수행합니다.  
코드는 다음과 같이 진행됩니다.  

```python
#Conv
def CBR2d (In_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):
    return nn.Sequential(
                        nn.Conv2d(in_channels=in_channels,
                        out_channels=out_channels, 
                        kernel_size=kernel_size,
                        stride=stride,
                        padding=padding,
                        bias=bias),
                        nn.BatchNorm2d(num_features=out_channels),
                        nn.ReLU()
                        )
```

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img7.png)

*Encode1*  
해당 코드는 zero-padding, stride=1을 줘서 Image의 size 변화를 만들어 냅니다. (padding을 1로 주는 경우도 있습니다.)  
skip-connection을 위한 Concat할 feature_map은 Max pooling 이전 Conv값인 enc1_2를 output으로 합니다.  

*Encoder2*, *Encoder3*, .. 
Encoder1에서 했던 내용과 유사합니다.  
channel 수를 64 -> 128, 128->256 로 변화시키고 나머지는 동일하게 진행합니다. 나머지 *Encoder4*, *Encoder5* 도 동일하게 진행합니다.  

여기서 주의해야할 점은 skip-connection을 위해서 enc1_2, enc2_2, enc3_2, enc4_2를 저장해야 하기 때문에 Network의 메모리도 무거워질 수 있습니다.  

이후 *Encoder5* 에서는 Decoder로 넘어갈 때, 다시 채널의 크기를 줄이면서 Image의 크기를 늘려야 하는 과정이 포함 됩니다.  
이 때, ConvTranspose2d를 이용해서 Upsampling을 합니다. 이 후, 나머지 decoder들도 Transposed Convolution을 이용해서 Upsampling을 합니다.

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img8.png)

Upconv4 이 후, 이전에 저장하고 있었던 enc4_2 이미지를 Concat 해야 합니다.  
하지만 이전에 이론에서 설명했듯이, enc4_2 이미지는 size가 맞지 않기 때문에 'crop_img' 과정을 거쳐야 합니다.  

  ![Untitled](/assets/images/AI-Images2/lv2_week11_4/img9.png)

</div>
</details>




## 2. 고민 내용, 결과 (과제 수행 과정, 결과물 정리)

### 프로젝트 수행

## 3. 피어세션 정리

### 피어세션

## 4. 학습 회고

[ 활동 ]

-

[ 회고 ]

- 

[ 다음 주 계획 ]

- 