---
title: "[네이버 부스트 캠프] AI-Tech-re - week4(4)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 18

오늘 한 일

- 강의 o
- ai-stages : 모델 정의
- 백준 알고리즘 - 가운데 수 & bfs 알고리즘
- 개인 회고

## 1. 강의 복습 내용

## 강의

## Training & Inference

EDA → 데이터 셋 → 모델

![Untitled](/assets/images/AI-Images2/week4/img19.png)

모델 학습 과정 : **Loss, Optim, Metric**

### Loss

loss 를 어떻게 활용할지?

- **Error Backpropagation**

    Loss 함수는 Output과 Target에 차이(Error 발생 함수 = Cost 함수)

    Backpropagation을 통해 Parameter를 업데이트.

    Loss도 어떤 방법을 쓰냐에 따라 다르게 변경될 수 있다.

    ![Untitled](/assets/images/AI-Images2/week4/img20.png)

- **loss는 nn.Modules family**

    Loss 또한 모듈을 상속하고 있다. → forward라는 함수를 가지고 있다. 

    즉, 학습한 모델이 Loss에도 연결될 수 있다. → chain을 가지고 온다. → Backward도 연결되어 grad 계산이 가능하다.

    ![Untitled](/assets/images/AI-Images2/week4/img21.png)

- **loss.backward()**

    loss = criterion은 nn.module을 상속한다. loss와 연결되어서 forward를 통해 만들어진output이 만들어진다. → chain 생성

    backward() 함수에 의해서 grad 값이 업데이트 된다. (required_grad = False 제외)

    ![Untitled](/assets/images/AI-Images2/week4/img22.png)

- **특별한 loss()**

    loss에 대한 cutom이 가능하다. Class에 따라 Error 만드는 과정을 바꿔줄 수 있다.

    ![Untitled](/assets/images/AI-Images2/week4/img23.png)

    클래스가 과연 100% 맞는 답인가? 비슷한 feature에 대해서 어떤 class가 100% 나눠지는 것이 아닌 다른 클래스에도 가깝다라는 것을 표현하기 위함. (soft)


### Optim

weight 파라미터에 어떠한 방법으로 업데이트를 시킬 것인가?

loss 값을 업데이트하는 주체

![Untitled](/assets/images/AI-Images2/week4/img24.png)

Learning Rate를 동적으로 조절하기 위해서는?

- StepLR

    : Step size에 따라 Learning Rate를 줄여준다.

![Untitled](/assets/images/AI-Images2/week4/img25.png)

![Untitled](/assets/images/AI-Images2/week4/img26.png)

- CosineAnnealing LR

: LR을 Cosine 형태에 따라 다르게 주는 방법

Local minimum에 빠지는 것을 빠르게 탈출할 수 있는 경우가 생긴다.

![Untitled](/assets/images/AI-Images2/week4/img27.png)

- ReduceLROnPlateau

: 기존의 LR방식이 아닌 미세하게 LR을 찾아 간다.

![Untitled](/assets/images/AI-Images2/week4/img28.png)

### Metric

: 모델의 평가, Score의 허와 실

객관적인 지표를 만들어서 모델의 성능 평가.

모델의 평가는 직접적으로 사용되지는 않지만, 모델을 선택하는 데 있어서 객관적인 지표를 쓸 수 있다. (현업에서는 결정해주지 않기에, 지표를 설정하는 것 또한 필요)

![Untitled](/assets/images/AI-Images2/week4/img29.png)

주로 사용하는 지표인 Accuracy만 따지고 보면, 다음과 같은 오류가 날 수 있다.

어느 정도, 적절히 맞춘 왼쪽 (0, 1) 이 아닌 한 쪽에만 치우쳐 맞춘 (0) 모델의 성능이 더 좋게 나올 수 있다.

![Untitled](/assets/images/AI-Images2/week4/img30.png)

위와 같은 오류를 방지하기 위해서 데이터 분포에 따라 Metric을 선택해야 한다. 클래스 별 성능에 대한 지표인 F1-Score를 추가.

[Training & Inference 2 는 다음 장에 이어서...](https://hyuns1102.github.io/ai/boostcourse/AItech-20/)

## 2. 고민 내용, 결과 (과제 수행 과정, 결과물 정리)

### 과제

freeze → 모든 레이어에 freeze 했을 때, 어떻게 될까?

```python
# for param in mnist_resnet18.parameters():
#     param.requires_grad = False
```

위와 같은 코드를 이용하려고 했다. 하지만 epoch 내에서 loss.backward에 ..

## 3. 피어세션 정리

오늘의 피어세션

1. 강의 요약

    - 내용: Training & Inference

2. 알고리즘 문제 풀기: 백준 2667번 단지번호 붙이기
3. 각자 제출한 코드 리뷰 - ( + 멘토님 리뷰 )

## 4. 학습 회고

- 코드 리뷰를 하면서 모델 커스터마이징 하는 것에 대해서 알았다.  
또한, 여러 세부사항에 대해서 따로 지정한 코드를 보고 내가 코드를 너무 대충 갖다 붙였다는 생각이 들었다.  
과제의 목적이 원래 만들어져 있는 코드를 사용하는 것이 아닌 가능한 세부 사항까지 조정하면서 만들어야 하는 것이었는데,  
너무 게으르게 했던 것 같다. -> 다음 팀별 과제에서는 정확한 **문제 정의**를 하고 문제 해결하자.

- 마스터 클래스에서 지금 나의 상태에 대해 잘 짚어주는 얘기들을 들었다. 누구보다 뒤쳐져 있는 것 같고, 혼자 힘들어하는 것 같다고 느끼는데,  
모두가 다 그렇다는 것이라고 알려줬다. 여기서 더 나아가기 위해서는 **자신의 실력을 인정하고, 상황을 인지**해서 **나에게 적합한 공부** (프로젝트 or 같이 할 수 있는 것 ex, 스터디, 강의 등등) 찾는 것이 맞다고 한다. 또한 업계가 좁으니 **항상 모두에게 잘 하자.! 어차피 힘들다!**