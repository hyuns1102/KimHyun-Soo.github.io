---
title: "[네이버 부스트 캠프] AI-Tech - Lv3 모델 경량화(3)"
categories: AI boostcourse
tags: python
published: trues
use_math: true
---

# 학습 기록 - 작은 모델, 좋은 파라미터 찾기: Data Augmentation & AutoML 결과 분석

<br>

## Introduction

<br>

Data Augmentation

- 기존 훈련 데이터에 변화를 가해, 데이터를 추가로 확보하는 방법
- 데이터의 Imbalance된 상황에서 활용가능
- 모델에 데이터의 불변하는 성질을 전달 -> Robust 해짐

경량화, AutoML 관점의 Augmentation

- 경량화와 직접적인 연결 x, 성능 향상을 위한 필수적인 기법
- Augmentation 또한 일종의 파라미터로, AutoML의 search space에 포함이 가능한 영역

Object detection에서의 대표적인 Augmentation 기법들

  ![tmp](/assets/images/AI-Images2/lv3_week3/img36.png)

  ![tmp](/assets/images/AI-Images2/lv3_week3/img37.png)

<br>

## Image Augmentation 논문 리뷰

<br>

Image Augmentation의 issue는 Task, Dataset의 종류에 따라 적절한 Augmentation의 종류, 조합, 정도(magnitude가 다를 것)

<br>

### 초간단 리뷰 : Auto Augment

Auto Augment : AutoML로 Augmentation policy를 찾자

- Data로부터 Data augmentation policy를 학습
- 총 5개의 sub policy, 각 sub policy는 2개의 augmentation type, 각 probability와 magnitude를 가짐

  ![tmp](/assets/images/AI-Images2/lv3_week3/img38.png)

- 좋은 성능을 보이지만, 학습에 많은 자원들이 필요

<br>

### 초간단 리뷰 : RandAugment

- 2개의 파라미터 (N: 한번에 몇개 적용, M: 공통 magnitude)로 search space를 극단적으로 줄임. (RandAug: 약 10^2, AutoAug: 약 10^32)
- 이 설정으로, policy를 찾는 여타 알고리즘과 거의 동등한 성능을 보임

  ![tmp](/assets/images/AI-Images2/lv3_week3/img39.png)

<br>

## 이후, 코드 설명 및 가상 시나리오

<br>

코드는 베이스라인 코드 참고

<br>

### 시나리오

```
PC 1대 정도 리소스(CPU: 8코어, GPU: v100 1대) 할당해드릴게요,  
cifar10 classification task에 대해서 파라미터는 적고, 성능 좋은 모델 하나 만들어주세요.  
내일(24시간)까지 부탁드립니다.
```

해당 task를 한 번 수행하는 데 걸리는 시간은? 모델의 크기에 따라 다르지만 약 3~4시간  
해당 리소스에서 최대 몇 개의 세션까지 구동가능한가? 대략 2~3개까지 가능

-> 일반적으로 100~200회는 되어야 경험적으로 좋은 결과를 얻어낼 수 있다는 것을 알 수 있다.  
하지만 이대로라면, 24회의 trial 밖에 못하는 상황

A. 시간 줄이기

- 학습 시간을 줄이기 위해 소규모 sample로 모델 찾기가 가능?
- 모델에 가장 큰 영향을 주는 인자만 search space로 넣고 싶다. 어떻게?
- 등등

직접 해봐야 함.

- 짧은 기한 임을 고려하여, 데이터셋 축소(Train: 5만장 -> 1만장(random sample), Test: 1만장); small cifar10
- Search space: 7개의 블록, 그 밖의 하이퍼파라미터는 전부 고정(모델 보다 중요하지 않다고 판단)
batchsize: 128, epoch: 200, SGD(+Momentum), Cosine annealing[11], Randaug 적용(N:2, M:15)

-> 30분에 1trial 적용 가능, 총 89회의 trial 이후, 유의미한 결과 도출

  ![tmp](/assets/images/AI-Images2/lv3_week3/img40.png){: width="70%" height="70%"}  

- 색이 밝을 수록 최신 순
- 상단으로 갈수록 많은 파라미터
- 우측으로 갈수록 좋은 성능

-> 대체적으로 우측 하단에 가깝게 분포 됨을 확인

<br>

### 결과

실제 데이터에서도 유사한 성능 값을 보여준다.  
완벽한 모델을 찾진 않아도 어느 정도 유사한 값을 뽑아낼 수 있다.

  ![tmp](/assets/images/AI-Images2/lv3_week3/img41.png)

  ![tmp](/assets/images/AI-Images2/lv3_week3/img42.png)

적합하고 적당한 크기의 approximation을 하더라도, 소기의 목적 달성 가능

<br>

### 결과 분석 및 논의

- AutoML로 데이터셋, task에 특화된 모델을 찾는 것이 가능 
- 현실적인 제약(시간, 리소스 등등)들을 해소하기 위한 엔지니어링은 (아직) 사람의 노하우가 필요 
- (심화) 데이터셋이 계속 추가되고 변화하는 현실 상황에서 이전 결과를 지속적으로 활용하려면 시스템을 어떻게 구성해야할까?(AutoML에서의 CI/CD)

<br>

# 최종 프로젝트

