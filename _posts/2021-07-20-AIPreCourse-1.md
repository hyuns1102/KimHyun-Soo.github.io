---
title: "[네이버 부스트 캠프] AI-Tech - 통계학 맛보기"
categories: AI precourse
tags: python
published: true
---

## 통계학 맛보기

---

> 이론이 너무 어려워서 가능한 다 정리하고 내 것으로 남기기 위해 포스트한다.

#### 통계적 모델링

통계적 모델링은 적절한 가정 위에서 **확률분포를 추정(inference)** 하는 것  
여기서 통계적 모델링과 기계학습은 공통적인 목표를 갖고 있다.  
그렇기에 우리는 여기서 통계적 모델링에서 얘기하는 확률 분포를 추정하기 위한 "가능도"를 얘기한다.

#### 모수란?

데이터가 주어졌을 때, 특정 확률분포를 따른다고 미리 가정한 후, 그 분포를 결정하는 "모수" (Parameter)를 추정하는 방법을  
**모수적 방법론**이라고 한다. ex) 정규분포는 분산, 표준편차를 모수로 한다.

특정 확률 분포 가정 x, 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀔 때, (모수가 없다는 뜻이 아니다.)  
**비모수 방법론**

확률 분포 가정 시, 데이터를 생성하는 원리를 먼저 고려하여 가정

베르누이 확률 분포 (이항 분포)의 예시)  
데이터를 모을수록 표본 평균의 확률 분포는 점점 정규분포로 간다. ( 중심극한정리 )
더 모을 수록 분산이 점점 작아진다. ( N이 커지기 때문에 )

#### 최대 가능도 추정법

표본평균이나 표본분산은 중요한 통계량이지만 확률분포마다 사용하는 모수가  
다르므로 적절한 통계량이 달라진다.

이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나는  
**최대가능도추정법(maximum likelihood estimation, MLE)**
