---
title: "[네이버 부스트 캠프] AI-Tech - Lv2 week5(1)"
categories: AI boostcourse
tags: python
published: true
use_math: true
---

## 학습기록 - 44

오늘 할 일  

- Advanced Object Detection 1

## 1. 강의 복습 내용

### Cascade RCNN

- Motivation

  - 다음 표처럼 1) IoU threshold에 따라 다르게 학습되었을 때 결과가 다름, 2) Input IoU가 높을수록 높은 IoU threshold에서 학습된 model이 더 좋은 결과를 냄.

    ![Untitled](/assets/images/AI-Images2/lv2_week8_1/img6.png){: width="30%" height="30%"}

  - IoU threshold에 따라 다르게 학습되었을 때 결과가 다름
  - 아래 표는 "예측된 박스"에 Ground Truth와 비교를 했을 때, 그 기준을 IoU threshold라고 놓는다. Threshold를 넘어가면 True, 넘어가지 않는다면 False로 한다. (그렇다면, 0.5는 AP50으로 될 수 있다.) -> 여기서 IoU Threshold는 AP의 IoU를 뜻한다.
  - 전반적인 AP의 경우, IoU threshold 0.5로 학습된 model이 성능이 가장 좋다.
  - 그러나 AP의 IoU threshold가 높아질수록 IoU threshold가 0.6, 0.7로 학습된 model의 성능이 좋다.

    ![Untitled](/assets/images/AI-Images2/lv2_week8_1/img7.png){: width="30%" height="30%"}

  정리하자면,

  - 학습되는 IoU에 따라 대응 가능한 IoU 박스가 다름
  - High Quality detection을 수행하기 위해서는 IoU threshold를 높여 학습할
  - 학습되는 IoU 에 따라 대응 가능한 IoU 박스가 다름
  - 그래프와 같이 high quality detection 을 수행하기 위해선 IoU threshold 를 높여 학습할 필요가 있음. 단, 성능 하락 문제 존재
  - 이를 해결하기 위해 Cascade RCNN을 제안 (순서를 가지고 학습하는 방법론)

- Faster R-CNN

RPN, Head Network를 학습시키기 위한 데이터셋 구성 필요  

Cascade RCNN은 IoU를 0.5, 0.6, 0.7 등을 기준으로 Head를 만들어 Detection 했을 때 어떻게 달라질까?에 기준을 둔다.  

- Method
  - 

### Deformable Convolution Network (DCN)

- Problems  
  Geometric Augmentation, Geometric invariant feature selection 

- Methods  
  일반 convolution에서 offset을 더 추가하여 학습시키면서 위치를 유동적으로 변화할 수 있게 한다. 이를 이용해 모양이 다른 객체를 볼 수 있게 만들어주는 것.  

### Transformer

- Overview  
  - NLP 에서 long range dependency 를 해결 이를 vision 에도 적용
  - Vision Transformer (ViT)
  - End to End Object Detection with Transformers (DETR)
  - Swin Transformer
  - **Self Attention**
  
- ViT (Vision Transformer)

- Swin Transformer

  - ViT의 문제점
    - 굉장히 많은량의 Data 를 학습하여야 성능이 나옴
    - Transformer 특성상 computational cost 큼
    - 일반적인 backbone 으로 사용하기 어려움

  - 해결법
    - CNN 과 유사한 구조로 설계
    - Window라는 개념을 이용해서 Cost를 줄임

### EfficientDet

- Model scaling
  모델의 크기가 클수록 성능이 더 좋아진다. 모델을 쌓을 때, 잘 쌓을 수 있는 부분이 존재할 것이다.  
  Model scaling에는 다음과 같은 방법들이 존재한다.  

  ![Untitled](/assets/images/AI-Images2/lv2_week8_1/img1.png){: width="50%" height="50%"}

  더 높은 정확도와 효율성을 가지면서 ConvNet의 크기를 키우는 방법 (scale up) 은 없을까?

### EfficientNet

- Background
  - 파라미터 수가 점점 많아지는 모델
  - ConvNet은 점점 더 커짐에 따라 더 정확해지고 있다.
  - 점점 빠르고 작은 모델에 대한 요구 증가
  - 효율성과 정확도의 trade-off를 통해 모델 사이즈를 줄이는 것이 일반적(MobileNets, SqueezeNets)
  - 하지만 , 큰 모델에 대해서는 어떻게 모델을 압축시킬지가 불분명함
  - 따라서 이 논문은 아주 큰 SOTA ConvNet 의 efficiency 를 확보하는 것을 목표로 함 -> 모델 스케일링을 통해 이 목표를 달성

- Scale up
  - Width Scaling

  - Depth Scaling

  - Resolution Scaling

  - Compound Scaling (위 세가지 특징을 모두 통합)

- Better Accuracy & Efficiency

  d, w, r : Scale Factor  
  Better Accuracy, Better Efficiency를 보장하려면?

    ![Untitled](/assets/images/AI-Images2/lv2_week8_1/img2.png){: width="50%" height="50%"}

    ![Untitled](/assets/images/AI-Images2/lv2_week8_1/img3.png){: width="50%" height="50%"}

  - Obsevation
    1. 네트워크의 폭, 깊이, 혹은 해상도를 키우면 정확도가 향상된다. 하지만 더 큰 모델에 대해서는 정확도 향상 정도가 감소한다.

        ![Untitled](/assets/images/AI-Images2/lv2_week8_1/img4.png){: width="50%" height="50%"}

    2. 더 나은 정확도와 효율성을 위해서는, ConvNet 스케일링 과정에서 네트워크의 폭 , 깊이 , 해상도의 균형을 잘 맞춰주는 것이 중요하다.

        ![Untitled](/assets/images/AI-Images2/lv2_week8_1/img5.png){: width="50%" height="50%"}

  - Compound Scaling Method

## 2. 고민 내용, 결과 (과제 수행 과정, 결과물 정리)

## 3. 피어세션 정리

## 4. 학습 회고

- 가면 갈수록 복잡한 모델들이 너무 많아지는 것 같다. 이해가 잘 안되고 정리도 힘들어진다.
- Efficient Net 추후 다시 복습 + Cascade R-CNN, Transformer.. 다!