---
title: "[네이버 부스트 캠프] AI-Tech - Lv3 모델 경량화(2)"
categories: AI boostcourse
tags: python
published: trues
use_math: true
---

## 학습 기록

## 좋은 모델과 파라미터 찾기 : AutoML 이론

Conventional DL pipeline이 어떤 문제를 해결? 목적?
Configuration의 특성?, 경량화 관점에서 AutoML이 어떤 의미를 가지는지?
AutoML Pipeline 구현 & 한계점, 현실적인 접근?

### Overview

#### Conventional DL Training Pipeline

"Data Engineering"이라 하면,  
우리가 이전에 했듯이 데이터를 정제하고 전처리를 거친 후,  
Feature Engineering을 진행한 후에, (주어진 데이터로 예측 모델의 문제를 잘 표현하는 features로 변형시키는 과정)  
적합한 모델을 선정해서 (ML Algorithm) 적합한 Hyperparameters를 선정합니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img16.png)

위와 같은 Data Engineering을 거친 후, 적합한 모델의 Architecture와 Hyperparameter (좋은 Configuration) 를 위해서 Train & Evalutation을 반복하게 됩니다.  
여기서 이 과정은 사람이 끊임없이 반복하게 됩니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img17.png)

#### Objectives of AutoML

위와 같은 과정들은 고객의 요구사항에 의해 새로운 데이터가 들어오거나 또 다른 예측 output을 내고 싶다면, 새롭게 tuning을 하게 됩니다.  

여기서 사람들이 작업해야하는 과정을 빼내고자 하는 것이 **Automated Machine Learning(AutoML)** 의 목표입니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img18.png)

AutoML의 문제 정의  
HyperParmeter Sample에 대해서 Algorithm, Data Train, Data Valid가 정의되어 있을 때, Loss가 가장 낮은 Hyperparameter를 정의해주는 것  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img19.png)

#### Properties of configurations in DL

DL model Configuration (Architecture, Hyperparameter)의 특징

1. 주요 타입 구분

    - Categorical
      - ex) optim : (Adam, AdamW, SGD) module : (Conv, BottleNeck, Residual block, ..)
    - Continuous
      - ex) learning rate, regularizer param, ...
    - Integer
      - ex) batch_size, epochs, .. 

2. ⭐Conditional⭐한 Configuration에 따라 Search space가 달라질 수 있습니다.  

    - Optimizer의 sample(e.g.SGD,Adam등등)에 따라서 optimizer parameter의 종류, search space도 달라짐 (e.g, optimizer에 따른 learning rate range 차이, SGD:momentum, Adam:alpha,beta1,beta2,..등등)
    - Module의 sample (e.g.VanillaConv, BottleNeck, InvertedResidual 등등)에 따라서 해당 module의 parameter의 종류,search space도 달라짐

#### 모델 경량화 관점에서의 AutoML

모델을 경량화하는 것은 두가지 관점이 존재합니다.  

기존 모델 경량화 vs 새로운 경량 모델 Search

- 기존 모델 경량화 : Pruning, Tensor decomposition, ... -> 이러한 기법들은 후처리가 있어야 성능이 나옵니다.  
- **새로운 경량 모델 Search** : NAS(Neural Architecture Search), Auto
 
### Basic Concept

#### AutoML Pipeline

일반적인 AutoML Pipeline  

Configuration : Backbone, hyperparam 모두 포괄  
Evaluate Objective : 어떤 Task에 따라 다르다? -> 성능, 속도 or 성능 등등 Task마다 원하는 수치 값을 설정해준다.  
Blackbox objective : 평가한 Objective값을 가지고 평가 지표를 최대로 만드는 람다를 찾는 것

  ![tmp](/assets/images/AI-Images2/lv3_week3/img20.png)

AutoML Pipeline 예시 : Bayesian Optimization (BO)  
Blackbox objective : Surrogate Function -> Acquisition Function  
Surrogate Function : $f(\lambda)$ 를 예측하는 Regression 모델  
Acquisition Function : 다음 $\lambda$ 를 시도하는 함수  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img21.png)

#### Bayesian Optimization (with Gaussian Process Regression)

Surrogate Function과 Acquisition Function을 자세하게 살펴보면,  
3번의 objective 계산 후, point가 업데이트 되는 것을 볼 수 있습니다.  
point가 업데이트 됨에 따라 Surrogate model이 업데이트 됩니다. 그에 따라, 점선과 보라색 영역이 줄어들면서 좀 더 정밀해집니다.  
Acquisition function은 다음 $\lambda$ 를 추천해주는 함수가 업데이트 됩니다.  
위와 같은 과정을 반복합니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img22.png)

간단 설명 : Gaussian Process Regression

```
Surrrogate function은 적절한 관계성을 가지는 Function을 찾아주는 것

Acquisition Function은 적절한 관계성 속에서 가장 적절한 위치를 찾아주는 것
```

#### Bayesian Optimization (with Gaussian Process Regression) - Surrogate Model

- 일반적인 Regression task : "Estimate the function f fits the data the most closely"  
  Set of train data: (X, Y), Set of the test data : (X*, Y*), $Y \approx f(X)+e$  

- 우리가 알고자 하는 특정 위치의 Y*값은 우리가 알고 있는 X, Y, X*들과 (positive건, negative건) 연관이 있지 않을까?  
  -> X, Y, X* 값으로부터 Y*를 추정, 연관에 대한 표현은 Kernel 함수 K로 표현

- f(x)를 "Possible output of the function f at input x"인 "Random variable"로 보고, 각 r.v.들이 Multivariate Gaussian distribution 관계에 있다고 가정  
= 함수들의 분포를 정의하고, 이 분포가 Multivariate Gaussian distribution을 따른다 가정  
= 함수 f가 **Gaussian process**를 따른다.  

식의 표현은 아래와 같습니다.

$$  \left[\begin{array}{l}\mathbf{f} \\ \mathbf{f}_{*}\end{array}\right] \sim \mathcal{N}\left(\mathbf{0},\left[\begin{array}{ll}K(X, X) & K\left(X, X_{*}\right) \\ K\left(X_{*}, X\right) & K\left(X_{*}, X_{*}\right)\end{array}\right]\right)  $$

[참고자료](https://www.edwith.org/bayesiandeeplearning/lecture/24811?isDesc=false)

- 결국, 위 식의 표현은 알고자 하는 값(test)과 알고있는 값(train)의 관계를 Multivariate Gaussian이라고 정의한 것이다.  

- Gaussian Identities (Gaussian의 marginal, conditional도 Gaussian)  
위와 같은 정의를 따를 때, Multivariate Gaussian의 marginal, conditional한 값도 Gaussian 분포를 따를 수 있다.  
이 식의 의미는 관계가 정의가 된다면 f와 데이터가 주어졌을 때, f*의 Conditional 분포를 정의해줄 수 있음을 의미합니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img23.png)

그림으로 보충 설명을 하자면, Multivariate Gaussian의 관계를 가질 때, 어느 위치에서 보더라도 모두 Gaussian Distribution을 이룬다.

  ![tmp](/assets/images/AI-Images2/lv3_week3/img24.png)

결론적으로, 이전에 설명했던 f와 f* 사이에 관계를 다음과 같이 Multivariate Gaussian으로 정의 된다면, X, f, X* (X* : 다음 데이터) 만으로 f*|X*의 분포를 평균, 분산으로 정의를 내릴 수 있습니다.  

  ![tmp](/assets/images/AI-Images2/lv3_week3/img25.png) 

- Surrogate Model(Function): $f(\lambda)$ 의 Regression model

  - 정의 : Objective $f(\lambda)$ 값을 예측하는 모델  
  지금까지 관측된 $f(\lambda)$ 가 있을 때, 새로운 $\lambda^{ * } $ 에 대한 objective $f(\lambda^{ * })$ 값은 얼마일까?

  - Objective를 estimate하는 surrogate model을 학습, 다음 좋은 $(\lambda)$ 를 선택하는 기준으로 사용

  - 대표적인 Surrogate model로는 Gaussian Process Regression(GPR) Model (Mean: 예측 f값, Var: uncertainty)

  [참고자료2-Visualization](https://distill.pub/2019/visual-exploration-gaussian-processes/)


#### Bayesian Optimization (with Gaussian Process Regression) - Acquisition Function

Acquisition Function : 다음은 어디를 trial하면 좋을까?

- Surrogate model의 output으로부터, 다음 시도해보면 좋을 $\lambda$ 를 계산하는 함수
- Exploration vs Exploitation  
  ("불확실한 지점 vs 알고있는 가장 좋은 곳"의 trade off)
- Acquisition function의 max 지점을 다음 iter에서 trial
- ex) Upper Confidence Bound(UCB)
  
  $$\alpha_{t}=\mu_{t-1}+\kappa \sigma_{t-1}$$
