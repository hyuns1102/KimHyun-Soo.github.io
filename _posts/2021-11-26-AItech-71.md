---
title: "[네이버 부스트 캠프] AI-Tech - Lv3 모델 경량화(5)"
categories: AI boostcourse
tags: python
published: trues
use_math: true
---

# 최종 프로젝트

YOLOv5 - DeepSort 를 쓴다고 해서 팀원들을 위해 정리한 Tutorial이다.  
팀원들이 모델을 같이 볼 때, 읽기 싫은 Readme.md를 step별로 가이드 라인을 세워봤고, 어떻게 학습을 시킬지 데모만 돌려봤다.  

별거 아니지만.. 그래도 오늘 열심히 했으니.. ㅋ



# YOLOv5 Tutorial

[https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch](https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch)

[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)

[https://github.com/ZQPei/deep_sort_pytorch](https://github.com/ZQPei/deep_sort_pytorch)

Yolov5-Deepsort model 은 Yolov5 model + Deepsort Algorithm이 합쳐진 모델입니다.
→ Detect가능한 Yolov5 모델이 tracking까지 가능하게 만들었습니다.

### 목표

저희는 Yolov5 모델을 학습시켜서 [Best.pt](http://Best.pt)를 뽑아, 해당 모델을 이용해서 tracking Inference까지 수행할 수 있도록 해야 합니다.

Inference 확인

Dataset 변환

Training

Use In YOLOv5+Deepsort Algorithm

### Inference

먼저, Yolov5_DeepSort - [README.md](https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/blob/master/README.md)에 대해서  Inference를 수행했을 때, 어떤 결과가 나오는 지 보는 과정입니다.

- **Inference**
    
    [Google Colaboratory](https://colab.research.google.com/drive/1w_CVXyfcxkbhu3EGjnGD760lpJIy_kDL?usp=sharing)
    
    github에 있는 tutorial과 동일합니다.
    추가로 youtube 영상에 대해 detect 가능한 영상도 만들 수 있는 코드를 주석처리했습니다.
    
- **결과**
    
    다음은 youtube 영상에 대해 Inference 수행 후, 결과입니다.
    
    ### 원본
    
    [https://www.youtube.com/watch?v=Zgi9g1ksQHc](https://www.youtube.com/watch?v=Zgi9g1ksQHc)
    
    ### Inference 후
    
    영상이 안올라가기에 zip파일로 업로드 했습니다.
    
    [Zgi9g1ksQHc.zip](/assets/images/AI-Images2/lv3_week3/Zgi9g1ksQHc.zip)
    
- **분석**
    
    ‼Inference 후, 빨리 감기가 되는 이상 현상 발생‼
    
    ‼동영상으로만 output으로 갖고옴‼
    

### Dataset

Dataset 같은 경우, Yolov5에서 training을 시키기 위해 format을 맞춰줘야 합니다.
[Yolov5의 설명](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)에서는 [Roboflow](https://app.roboflow.com/)를 이용해서 YOLOv5 - pytorch format을 만드는 것을 권장하고 있습니다.
여기서 해야할 일은 coco format → YOLOv5 pytorch format 으로 변환하는 일입니다.

- **Sample** **Dataset**
    
    [ptop.v3-coco.coco.zip](/assets/images/AI-Images2/lv3_week3/ptop.v3-coco.coco.zip)
    
    ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled.png)
    
    in train
    
    ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%201.png)
    
- **Roboflow - Format 변환**
    
    
    Sample Dataset을 이용해서 변환 과정입니다.
    
    - ### Step1. Login
    
      ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%202.png)
    
    - **Step2. Create New Project**
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%203.png)
        
        Project 이름 설정
        Annotation Group (최상위 카테고리 입니다. 큰 영향을 주는 것 같지 않습니다.)
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%204.png)
        
    - **Step3. Image Upload**
        
        coco.json 파일을 포함해서 모든 이미지를 올려주세요.
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%205.png)
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%206.png)
        
        다 올리면, 'Finish Uploading' 버튼을 클릭해주세요.
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%207.png)
        
        Split set을 만들 것인지 판단 후, 결정합니다.
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%208.png)
        
        분리된 이미지의 Preprocessing과 Augmentation을 추가해서 넣을 것인지 선택하세요.
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%209.png)
        
    - **Step4. Export, format 변환**
        
        데이터를 추출하고 format을 Yolov5 format으로 변환합니다.
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%2010.png)
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%2011.png)
        
        여기서 show download code는 Api key로 받아서 코드로 바로 쓸 수 있게 만들어줍니다.
        
        ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%2012.png)
        
         
        
    
    **결과**
    
    ![Untitled](/assets/images/AI-Images2/lv3_week3/Untitled%2013.png)
    

[test2.v1-test.yolov5pytorch.zip](/assets/images/AI-Images2/lv3_week3/test2.v1-test.yolov5pytorch.zip)

### Training

위에서 만든 YOLOv5 format을 이용해서 Train을 진행합니다.

우선적으로, Yolov5_DeepSort_Pytorch를 clone 해주세요.

☢ Data Root는 편한곳으로 맞추면 됩니다.

☢ 기본적인 train은 tensorboard에서 결과를 볼 수 있습니다.

- **Step 1. Data Root 맞추기**
    
    이전 과정에서 새롭게 생성한 YOLOv5 format Dataset의 압축을 풀어 아래 위치에 올려줍니다.
    
    ```python
    # ├── yolov5
    #     └── data
    #         └── [Sample_Dataset]
    #             └── train
    #             └── valid
    #             └── test
    #         └── data.yaml
    ```
    
    예시 속 data.yaml 파일은 다음과 같이 되어 있습니다.
    새롭게 설정한 train, valid 경로로 수정해주세요.
    
    ```python
    train: ../train/images # 경로수정
    val: ../valid/images # 경로수정
    
    nc: 4
    names: ['bike', 'car', 'person', 'scooter']
    ```
    

- **Step 2. train 실행**

    ```python
    $ python [train.py](http://train.py/) **--data data.yaml** **--epochs 10**
    ```